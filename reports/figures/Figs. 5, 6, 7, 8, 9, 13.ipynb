{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "362f31f8-2b16-4e2d-8313-f9a32b62500a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figures 5, 6, 7, 8, 9, and 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1120ff1-9bbf-4fe0-beb4-0f934eeff3e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cff630a-c346-48b0-9ae2-65eca67b8d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import contextily as ctx\n",
    "import shapely\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, Point, MultiLineString, Polygon, MultiPolygon\n",
    "from scipy import interpolate\n",
    "from itertools import islice\n",
    "from fiona import path\n",
    "from rasterio.transform import xy\n",
    "import concurrent.futures\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch, Polygon\n",
    "\n",
    "from matplotlib.colors import Normalize, LinearSegmentedColormap\n",
    "from matplotlib import cm\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "from shapely import LineString\n",
    "from shapely.geometry import shape as shp_shape\n",
    "from shapely.ops import unary_union, linemerge, polygonize\n",
    "from rasterio import features\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.legend_handler import HandlerTuple, HandlerBase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1cf866-c7b8-440f-a8d6-0e92ecd7ffe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "difference_threshold = 0.33\n",
    "\n",
    "THRESH_MIN = 0.33   # keep >= 0.5 ft\n",
    "THRESH_MAX = 3.5   # drop outliers > threshold in ft  (adjust if you want)\n",
    "MIN_AREA_M2 = 20.0e5  # drop polygons smaller than this area (in m^2); set to 0 to keep all, used in mapping the boundary of the transition zone\n",
    "SIMPLIFY_TOL = 10\n",
    "\n",
    "data_dir1 = '/Volumes/lwi/default/transition-zone-data/pilot_reanalysis/output_data'\n",
    "data_dir_pluvial = '/Volumes/lwi/default/transition-zone-data/pilot_reanalysis/prod_rerun_5k/tropical_pluvial_rasters'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfc5c4d2-c3b1-43d4-8245-111c06d52baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8680aca-6573-445a-a6e1-765de6ca93dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_raster_along_line(raster_dataset, line_feature, num_points=1000):\n",
    "    \"\"\"\n",
    "    Extract raster values along a line feature and calculate distances.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raster_dataset : xarray.Dataset or xarray.DataArray\n",
    "        The raster data\n",
    "    line_feature : GeoSeries or GeoDataFrame with LineString or MultiLineString geometry\n",
    "        The line along which to extract values\n",
    "    num_points : int, optional\n",
    "        Number of points to sample along the line\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (distances, values)\n",
    "        distances: numpy array of distances along the line\n",
    "        values: numpy array of raster values at each point\n",
    "    \"\"\"\n",
    "    # Get the first line if multiple lines are present\n",
    "    if isinstance(line_feature, gpd.GeoDataFrame):\n",
    "        line = line_feature.geometry.iloc[0]\n",
    "    else:\n",
    "        line = line_feature.geometry\n",
    "    \n",
    "    # Handle MultiLineString by converting to LineString\n",
    "    if isinstance(line, MultiLineString):\n",
    "        # Convert MultiLineString to a single LineString by merging all segments\n",
    "        # This assumes the segments can be meaningfully connected\n",
    "        linestrings = list(line.geoms)\n",
    "        coords = []\n",
    "        for ls in linestrings:\n",
    "            coords.extend(list(ls.coords))\n",
    "        line = LineString(coords)\n",
    "    elif not isinstance(line, LineString):\n",
    "        raise ValueError(\"Input must be a LineString or MultiLineString geometry\")\n",
    "    \n",
    "    # Create evenly spaced points along the line\n",
    "    distances = np.linspace(0, line.length, num_points)\n",
    "    points = [line.interpolate(distance) for distance in distances]\n",
    "    \n",
    "    # Get coordinates of points\n",
    "    coords = [(point.x, point.y) for point in points]\n",
    "    \n",
    "    # Extract values from raster at each point\n",
    "    if isinstance(raster_dataset, xr.Dataset):\n",
    "        # Select the first data variable if it's a dataset\n",
    "        var_name = list(raster_dataset.data_vars)[0]\n",
    "        da = raster_dataset[var_name]\n",
    "    else:\n",
    "        da = raster_dataset\n",
    "    \n",
    "    # Get the raster values at each point\n",
    "    values = []\n",
    "    for x, y in coords:\n",
    "        # Convert x,y to raster indices\n",
    "        # This assumes the xarray has coordinates with names 'x' and 'y'\n",
    "        # Adjust if your coordinate names are different (e.g., 'lon', 'lat')\n",
    "        try:\n",
    "            # Method 1: Using xarray's sel method with nearest neighbor\n",
    "            val = da.sel(x=x, y=y, method=\"nearest\").values.item()\n",
    "        except (KeyError, ValueError):\n",
    "            try:\n",
    "                # Method 2: Try with different coordinate names\n",
    "                val = da.sel(lon=x, lat=y, method=\"nearest\").values.item()\n",
    "            except (KeyError, ValueError):\n",
    "                # If coordinate names are unknown, just use NaN\n",
    "                val = np.nan\n",
    "        values.append(val)\n",
    "    \n",
    "    return distances, np.array(values)\n",
    "\n",
    "def ensure_connected_linestring(multiline):\n",
    "    \"\"\"\n",
    "    Convert a MultiLineString to a single LineString with proper connectivity\n",
    "    between segments.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    multiline : MultiLineString or LineString\n",
    "        Input line geometry\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    LineString\n",
    "        A properly connected LineString\n",
    "    \"\"\"\n",
    "    if isinstance(multiline, LineString):\n",
    "        return multiline\n",
    "    \n",
    "    # Extract all segments from the MultiLineString\n",
    "    segments = list(multiline.geoms)\n",
    "    if not segments:\n",
    "        raise ValueError(\"Empty MultiLineString provided\")\n",
    "    \n",
    "    # Start with the first segment\n",
    "    result_coords = list(segments[0].coords)\n",
    "    segments_used = [0]\n",
    "    \n",
    "    # Keep track of both ends of our working LineString\n",
    "    start_point = Point(result_coords[0])\n",
    "    end_point = Point(result_coords[-1])\n",
    "    \n",
    "    # Keep connecting segments until all are used\n",
    "    while len(segments_used) < len(segments):\n",
    "        best_segment = None\n",
    "        best_distance = float('inf')\n",
    "        best_is_reversed = False\n",
    "        best_idx = -1\n",
    "        \n",
    "        # Find the closest segment to either end of our working LineString\n",
    "        for i, segment in enumerate(segments):\n",
    "            if i in segments_used:\n",
    "                continue\n",
    "                \n",
    "            seg_start = Point(segment.coords[0])\n",
    "            seg_end = Point(segment.coords[-1])\n",
    "            \n",
    "            # Check distances to both ends of our working LineString\n",
    "            dist_start_to_start = start_point.distance(seg_start)\n",
    "            dist_start_to_end = start_point.distance(seg_end)\n",
    "            dist_end_to_start = end_point.distance(seg_start)\n",
    "            dist_end_to_end = end_point.distance(seg_end)\n",
    "            \n",
    "            # Find the minimum distance and corresponding configuration\n",
    "            min_dist = min(dist_start_to_start, dist_start_to_end, \n",
    "                          dist_end_to_start, dist_end_to_end)\n",
    "            \n",
    "            if min_dist < best_distance:\n",
    "                best_distance = min_dist\n",
    "                best_segment = segment\n",
    "                best_idx = i\n",
    "                \n",
    "                # Determine if we need to reverse the segment and where to connect it\n",
    "                if min_dist == dist_start_to_start:\n",
    "                    # Connect to start, reverse segment\n",
    "                    best_is_reversed = True\n",
    "                    connect_to_start = True\n",
    "                elif min_dist == dist_start_to_end:\n",
    "                    # Connect to start, don't reverse\n",
    "                    best_is_reversed = False\n",
    "                    connect_to_start = True\n",
    "                elif min_dist == dist_end_to_start:\n",
    "                    # Connect to end, don't reverse\n",
    "                    best_is_reversed = False\n",
    "                    connect_to_start = False\n",
    "                else:  # min_dist == dist_end_to_end\n",
    "                    # Connect to end, reverse segment\n",
    "                    best_is_reversed = True\n",
    "                    connect_to_start = False\n",
    "        \n",
    "        if best_segment is None:\n",
    "            # This shouldn't happen if the MultiLineString is valid\n",
    "            break\n",
    "        \n",
    "        # Get coords from the best segment\n",
    "        new_coords = list(best_segment.coords)\n",
    "        if best_is_reversed:\n",
    "            new_coords.reverse()\n",
    "        \n",
    "        # Add to result_coords\n",
    "        if connect_to_start:\n",
    "            # Remove the first point which would be a duplicate\n",
    "            result_coords = new_coords + result_coords[1:]\n",
    "            start_point = Point(result_coords[0])\n",
    "        else:\n",
    "            # Remove the first point which would be a duplicate\n",
    "            result_coords = result_coords[:-1] + new_coords\n",
    "            end_point = Point(result_coords[-1])\n",
    "        \n",
    "        segments_used.append(best_idx)\n",
    "    \n",
    "    return LineString(result_coords)\n",
    "\n",
    "def group_and_average(xs, threshold=2.5):\n",
    "    xs_sorted = sorted(xs)\n",
    "    groups = []\n",
    "    current_group = [xs_sorted[0]]\n",
    "    for x in xs_sorted[1:]:\n",
    "        if abs(x - current_group[-1]) <= threshold:\n",
    "            current_group.append(x)\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [x]\n",
    "    groups.append(current_group)\n",
    "    return [sum(g)/len(g) for g in groups]   \n",
    "\n",
    "# ---------- helpers ----------\n",
    "def set_integer_yticks(ax, nbins=5):\n",
    "    \"\"\"Set y-axis ticks to integers only with controlled spacing.\"\"\"\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True, nbins=nbins))\n",
    "\n",
    "def all_level_crossings(x, y, level=0.5):\n",
    "    \"\"\"Return sorted list of x where y crosses 'level' (linear interp).\"\"\"\n",
    "    x = np.asarray(x); y = np.asarray(y)\n",
    "    d = y - level\n",
    "    xs = []\n",
    "    sign_change = (np.sign(d[:-1]) * np.sign(d[1:]) < 0) | (d[:-1] == 0) | (d[1:] == 0)\n",
    "    idxs = np.where(sign_change)[0]\n",
    "    for i in idxs:\n",
    "        x0, x1 = x[i], x[i+1]\n",
    "        y0, y1 = y[i], y[i+1]\n",
    "        if d[i] == 0:\n",
    "            xs.append(float(x0))\n",
    "        elif d[i+1] == 0:\n",
    "            xs.append(float(x1))\n",
    "        elif y1 != y0:\n",
    "            t = (level - y0) / (y1 - y0)\n",
    "            if 0 <= t <= 1:\n",
    "                xs.append(float(x0 + t * (x1 - x0)))\n",
    "    # include flat segments exactly at level\n",
    "    flat = np.where((d[:-1] == 0) & (d[1:] == 0))[0]\n",
    "    for i in flat:\n",
    "        xs.extend([float(x[i]), float(x[i+1])])\n",
    "    xs = sorted(xs)\n",
    "    uniq = []\n",
    "    for v in xs:\n",
    "        if not uniq or abs(v - uniq[-1]) > 1e-6:\n",
    "            uniq.append(v)\n",
    "    return uniq\n",
    "\n",
    "def draw_cftz(left_ax, right_ax, x_left, x_right, mode=\"between\", label=\"CFTZ\"):\n",
    "    \"\"\"\n",
    "    Draw verticals at x_left and x_right on both axes.\n",
    "    mode=\"between\": dotted span between x_left..x_right\n",
    "    mode=\"to_right\": dotted span from x_right..right edge\n",
    "    Label is centered over the span and placed just BELOW the dotted line.\n",
    "    \"\"\"\n",
    "    for ax in (left_ax, right_ax):\n",
    "        ax.axvline(x_left,  color='black', lw=1.0)\n",
    "        ax.axvline(x_right, color='black', lw=1.0)\n",
    "\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        yspan = ymax - ymin\n",
    "        yline = ymax - 0.03 * yspan   # a hair below top\n",
    "        # span endpoints\n",
    "        if mode == \"between\":\n",
    "            x0, x1 = x_left, x_right\n",
    "        else:  # to_right\n",
    "            # use current axis max\n",
    "            xlim_max = ax.get_xlim()[1]\n",
    "            x0, x1 = x_right, xlim_max\n",
    "\n",
    "        ax.hlines(yline, x0, x1, linestyles=':', colors='black', lw=1.2)\n",
    "\n",
    "        # centered label, BELOW the dotted line\n",
    "        xmid = 0.5 * (x0 + x1)\n",
    "        ax.text(xmid, yline - 0.02 * yspan, label,\n",
    "                ha='center', va='top', fontsize=10, color='black', clip_on=False)\n",
    "        \n",
    "# ---------------- helper: draw transect with km ticks/labels ----------------\n",
    "def overlay_transect(ax, line: LineString, km_ticks=(0,20,40,60,80, 100, 120),\n",
    "                     line_lw=3.0, dot_size=22, label_fontsize=9,\n",
    "                     ensure_north_start=False, label_position='center'):\n",
    "    \"\"\"\n",
    "    Draw the Amite transect on ax with markers/labels at given km distances.\n",
    "    - ensure_north_start=True will flip the line so that the 0-km end is the\n",
    "      northernmost point (top of map). Leave False to keep original direction.\n",
    "    - label_position: 'left', 'center', or 'right' to position the label relative to the symbol.\n",
    "    \"\"\"\n",
    "    # If requested, flip so that \"0\" is the northern (top) end\n",
    "    if ensure_north_start:\n",
    "        x0, y0 = list(line.coords)[0]\n",
    "        x1, y1 = list(line.coords)[-1]\n",
    "        if y0 < y1:  # start is south of end; reverse so 0 is at the top\n",
    "            line = LineString(list(line.coords)[::-1])\n",
    "\n",
    "    # draw the line (bold white)\n",
    "    xs, ys = np.array(line.coords.xy[0]), np.array(line.coords.xy[1])\n",
    "    ax.plot(xs, ys, color='black', lw=line_lw, zorder=10, solid_capstyle='round')\n",
    "\n",
    "    # total length (meters) and valid tick distances\n",
    "    Lm = line.length\n",
    "    tick_m = [k*1000 for k in km_ticks if k*1000 <= Lm]\n",
    "\n",
    "    # interpolate points, draw dots and labels\n",
    "    for idx, (k, dm) in enumerate(zip(km_ticks, [k*1000 for k in km_ticks])):\n",
    "        if dm > Lm:\n",
    "            continue\n",
    "        pt = line.interpolate(dm)\n",
    "        px, py = pt.x, pt.y\n",
    "        # dot: white fill, black edge\n",
    "        ax.scatter([px], [py], s=dot_size, facecolor='white',\n",
    "                   edgecolor='black', linewidths=1.2, zorder=11)\n",
    "        # label position adjustment\n",
    "        if label_position == 'left':\n",
    "            ha = 'right'\n",
    "            offset = -0.012\n",
    "        elif label_position == 'right':\n",
    "            ha = 'left'\n",
    "            offset = 0.012\n",
    "        else:  # center\n",
    "            ha = 'center'\n",
    "            offset = 0\n",
    "\n",
    "        # label slightly above the dot\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        offs = offset * (ymax - ymin)\n",
    "        # Add 'km' to first and last tick label\n",
    "        if idx == 0 or idx == len(km_ticks) - 1:\n",
    "            label = f\"{k} km\"\n",
    "        else:\n",
    "            label = f\"{k}\"\n",
    "        ax.text(px + offs, py + offs, label, ha=ha, va='bottom',\n",
    "                fontsize=label_fontsize, color='white',\n",
    "                zorder=12,\n",
    "                path_effects=[__import__('matplotlib.patheffects').patheffects.withStroke(\n",
    "                    linewidth=2, foreground='black')])\n",
    "        \n",
    "def mask_to_outline_gdf(mask01, ref_da, min_area_m2=MIN_AREA_M2):\n",
    "    \"\"\"Polygonize mask==1, dissolve, optional area filter, return boundaries as GeoDataFrame.\"\"\"\n",
    "    if mask01.sum() == 0:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "\n",
    "    geoms = [shp_shape(g) for g, val in features.shapes(mask01, transform=ref_da.rio.transform()) if int(val) == 1]\n",
    "    if not geoms:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "\n",
    "    # dissolve and clean\n",
    "    dissolved = unary_union(geoms).buffer(0)\n",
    "    polys = gpd.GeoDataFrame(geometry=[dissolved], crs=ref_da.rio.crs).explode(index_parts=False).reset_index(drop=True)\n",
    "\n",
    "    # optional area filter (works if CRS is projected in meters; EPSG:26915 is)\n",
    "    if min_area_m2 and min_area_m2 > 0:\n",
    "        polys = polys[polys.geometry.area >= min_area_m2]\n",
    "        if polys.empty:\n",
    "            return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "\n",
    "    # boundaries\n",
    "    return gpd.GeoDataFrame(geometry=polys.boundary, crs=ref_da.rio.crs)\n",
    "\n",
    "\n",
    "\n",
    "# Inputs already in your session:\n",
    "# diff_10, diff_50, diff_100, diff_500  (xarray/rioxarray DataArrays, same grid/CRS)\n",
    "\n",
    "\n",
    "\n",
    "def make_band_mask(da, lo=THRESH_MIN, hi=THRESH_MAX):\n",
    "    \"\"\"Boolean mask for lo <= da <= hi (finite only), returned as uint8 0/1.\"\"\"\n",
    "    v = da.values\n",
    "    m = np.isfinite(v) & (v >= lo) & (v <= hi)\n",
    "    return m.astype(\"uint8\")\n",
    "\n",
    "def compound_masks(prev_mask, new_mask):\n",
    "    \"\"\"Ensure monotonic growth: logical OR with previous.\"\"\"\n",
    "    return new_mask if prev_mask is None else ((prev_mask > 0) | (new_mask > 0)).astype(\"uint8\")\n",
    "\n",
    "\n",
    "\n",
    "def mask_to_outline_gdf(mask01, ref_da, min_area_m2=MIN_AREA_M2, simplify_tol=SIMPLIFY_TOL):\n",
    "    if mask01.sum() == 0:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "\n",
    "    geoms = [shp_shape(g) for g, val in features.shapes(mask01, transform=ref_da.rio.transform()) if int(val) == 1]\n",
    "    if not geoms:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "\n",
    "    # dissolve and clean\n",
    "    dissolved = unary_union(geoms).buffer(0)\n",
    "    dissolved = _remove_small_inners(dissolved, 20e5)\n",
    "    # Remove small speckles (area filter)\n",
    "    if dissolved.geom_type == \"MultiPolygon\":\n",
    "        dissolved = [p for p in dissolved.geoms if p.area >= min_area_m2]\n",
    "        if not dissolved:\n",
    "            return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "        dissolved = unary_union(dissolved)\n",
    "    elif dissolved.area < min_area_m2:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=ref_da.rio.crs)\n",
    "\n",
    "    # Simplify geometry\n",
    "    simplified = dissolved.simplify(simplify_tol, preserve_topology=True)\n",
    "    polys = gpd.GeoDataFrame(geometry=[simplified], crs=ref_da.rio.crs).explode(index_parts=False).reset_index(drop=True)\n",
    "\n",
    "    return gpd.GeoDataFrame(geometry=polys.boundary, crs=ref_da.rio.crs)\n",
    "\n",
    "def save_geojson(gdf, path):\n",
    "    if gdf.empty:\n",
    "        print(f\"[save] {path}: empty, skipped.\")\n",
    "    else:\n",
    "        gdf.to_file(path, driver=\"GeoJSON\")\n",
    "        print(f\"[save] wrote {path} ({len(gdf)} parts)\")\n",
    "\n",
    "\n",
    "\n",
    "def _remove_small_inners(geom, min_area_m2):\n",
    "    if geom.is_empty:\n",
    "        return geom\n",
    "    if geom.geom_type == \"Polygon\":\n",
    "        # keep only interior rings that form polygons above threshold\n",
    "        new_interiors = []\n",
    "        for ring in geom.interiors:\n",
    "            poly = Polygon(ring)\n",
    "            if poly.area >= min_area_m2:\n",
    "                new_interiors.append(ring)\n",
    "        return Polygon(geom.exterior, new_interiors)\n",
    "\n",
    "    elif geom.geom_type == \"MultiPolygon\":\n",
    "        return MultiPolygon([_remove_small_inners(p, min_area_m2) for p in geom.geoms])\n",
    "    else:\n",
    "        return geom\n",
    "    \n",
    "def get_transition_polys(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Robustly select the 'Transition' zone polygons by:\n",
    "      A) name-like columns containing 'transition' (case-insensitive)\n",
    "      B) style/color columns (fill/stroke/color/colour) containing 'yellow'\n",
    "         or common yellow-ish hex/RGB hints\n",
    "    \"\"\"\n",
    "    if gdf.empty:\n",
    "        return gdf\n",
    "\n",
    "    # A) Token search in any string/object column\n",
    "    token_mask = np.zeros(len(gdf), dtype=bool)\n",
    "    TOKENS = (\"transition\", \"transitional\")\n",
    "    for col in gdf.columns:\n",
    "        if gdf[col].dtype == \"object\":\n",
    "            s = gdf[col].astype(str).str.lower()\n",
    "            for t in TOKENS:\n",
    "                token_mask |= s.str.contains(t, regex=False)\n",
    "\n",
    "    # B) Style/color hints\n",
    "    style_mask = np.zeros(len(gdf), dtype=bool)\n",
    "    STYLE_COLS = [c for c in gdf.columns if c.lower() in {\"fill\",\"stroke\",\"color\",\"colour\"}]\n",
    "    # yellow-ish values to catch common encodings\n",
    "    YELLOW_HINTS = (\n",
    "        \"yellow\",          # named\n",
    "        \"#ff0\", \"#ffff00\", # classic hex\n",
    "        \"#ffcc00\", \"#ffd700\", \"#fdd835\", \"#ffc107\",  # common yellows\n",
    "        \"255,255,0\", \"rgb(255,255,0)\"                # RGB text\n",
    "    )\n",
    "    for sc in STYLE_COLS:\n",
    "        s = gdf[sc].astype(str).str.lower()\n",
    "        m = np.zeros(len(gdf), dtype=bool)\n",
    "        for y in YELLOW_HINTS:\n",
    "            m |= s.str.contains(y, regex=False)\n",
    "        style_mask |= m\n",
    "\n",
    "    sel = token_mask | style_mask\n",
    "    trans = gdf.loc[sel].copy()\n",
    "\n",
    "    # If multiple parts, dissolve to a single feature for a clean boundary\n",
    "    if not trans.empty:\n",
    "        trans = trans.dissolve().reset_index(drop=True)\n",
    "\n",
    "    return trans\n",
    "\n",
    "def _remove_small_inners(geom, min_area_m2):\n",
    "    if geom.is_empty:\n",
    "        return geom\n",
    "    if geom.geom_type == \"Polygon\":\n",
    "        new_interiors = []\n",
    "        for ring in geom.interiors:\n",
    "            poly = Polygon(ring)\n",
    "            if poly.area >= min_area_m2:\n",
    "                new_interiors.append(ring)\n",
    "        return Polygon(geom.exterior, new_interiors)\n",
    "    elif geom.geom_type == \"MultiPolygon\":\n",
    "        return MultiPolygon([_remove_small_inners(p, min_area_m2) for p in geom.geoms])\n",
    "    else:\n",
    "        return geom\n",
    "\n",
    "def simplify_transition_gdf(\n",
    "    gdf, min_area_m2=MIN_AREA_M2, simplify_tol=SIMPLIFY_TOL):\n",
    "    if gdf.empty:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=gdf.crs)\n",
    "    geoms = list(gdf.geometry)\n",
    "    dissolved = unary_union(geoms).buffer(0)\n",
    "    dissolved = _remove_small_inners(dissolved, 20e5)\n",
    "    if dissolved.geom_type == \"MultiPolygon\":\n",
    "        dissolved = [p for p in dissolved.geoms if p.area >= min_area_m2]\n",
    "        if not dissolved:\n",
    "            return gpd.GeoDataFrame(geometry=[], crs=gdf.crs)\n",
    "        dissolved = unary_union(dissolved)\n",
    "    elif dissolved.area < min_area_m2:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=gdf.crs)\n",
    "    simplified = dissolved.simplify(simplify_tol, preserve_topology=True)\n",
    "    polys = gpd.GeoDataFrame(geometry=[simplified], crs=gdf.crs).explode(index_parts=False).reset_index(drop=True)\n",
    "    return gpd.GeoDataFrame(geometry=polys.boundary, crs=gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921523f1-a847-4c2b-84ef-55cd8e6a62a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63da2772-ae82-4aa8-8b9c-b0dcff5df286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Load rasters origin\n",
    "# ally created by Purdue, but which are not correct for comparison.\n",
    "combined_fig_10 = rioxarray.open_rasterio(f'{data_dir1}/Spline_Tension_T10_joint_depth_adj.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_fig_50 = rioxarray.open_rasterio(f'{data_dir1}/Spline_Tension_T50_joint_depth_adj.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_fig_100 = rioxarray.open_rasterio(f'{data_dir1}/Spline_Tension_T100_joint_depth_adj.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "\n",
    "combined_fig_10_1 = rioxarray.open_rasterio(f'{data_dir1}/Spline_T10_joint_depth1.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_fig_50_1 = rioxarray.open_rasterio(f'{data_dir1}/Spline_T50_joint_depth1.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_fig_100_1 = rioxarray.open_rasterio(f'{data_dir1}/Spline_T100_joint_depth1.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4039e7d5-41c2-46ff-9b3d-a19db689d956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Load TC only Compound Flood Rasters\n",
    "compound_10 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_compound_0010_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "compound_50 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_compound_0050_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "compound_100 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_compound_0100_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "compound_500 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_compound_0500_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "\n",
    "#Load TC and non TC combined compound Flood rasters\n",
    "combined_10 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_combined_compound_0010_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_50 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_combined_compound_0050_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_100 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_combined_compound_0100_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "combined_500 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_combined_compound_0500_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "\n",
    "combined_10 = (combined_10.rio.reproject_match(compound_10))\n",
    "combined_50 = (combined_50.rio.reproject_match(compound_50))\n",
    "combined_100 = (combined_100.rio.reproject_match(compound_100))\n",
    "combined_500 = (combined_500.rio.reproject_match(compound_500))\n",
    "\n",
    "#Load surge only, riverine only, and pluvial only rasters.\n",
    "surge_10 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_surge_only_0010_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "surge_50 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_surge_only_0050_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "surge_100 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_surge_only_0100_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "surge_500 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_surge_only_0500_YR_WSE_no_aleatory_bartlett_edits.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "\n",
    "riverine_10 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_riverine_only_0010_YR_WSE_revised.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "riverine_50 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_riverine_only_0050_YR_WSE_revised.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "riverine_100 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_riverine_only_0100_YR_WSE_revised.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "riverine_500 = rioxarray.open_rasterio(f'{data_dir1}/EJPMOS_tropical_riverine_only_0500_YR_WSE_revised.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "\n",
    "pluvial_10 = rioxarray.open_rasterio(f'{data_dir_pluvial}/EJPMOS_tropical_pluvial_0010_YR_WSE_os_no_aleatory.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "pluvial_50 = rioxarray.open_rasterio(f'{data_dir_pluvial}/EJPMOS_tropical_pluvial_0050_YR_WSE_os_no_aleatory.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "pluvial_100 = rioxarray.open_rasterio(f'{data_dir_pluvial}/EJPMOS_tropical_pluvial_0100_YR_WSE_os_no_aleatory.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "pluvial_500 = rioxarray.open_rasterio(f'{data_dir_pluvial}/EJPMOS_tropical_pluvial_0500_YR_WSE_os_no_aleatory.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "\n",
    "#load elevation and Amite river line data.\n",
    "grade_elev = rioxarray.open_rasterio(f'{data_dir1}/amite_ground_elev_prod.tif').rio.reproject(\"EPSG:26915\").sel(band = 1)\n",
    "amite_line = gpd.read_file(f'{data_dir1}/amite_line_pass_manchac_centered_userpoints.json').to_crs('EPSG:26915')\n",
    "#amite_line_extended = gpd.read_file(f'{data_dir1}/amite_line_extended.json').to_crs('EPSG:26915')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d76ca5e7-fabc-40e8-a8e4-ce3700fe5847",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Take greater of the WSE or ground elevation\n",
    "Also only take the surge values where the pluvial is valid to remove the spurious surge conditions are the boundary of the model where the surge condition is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "804943fb-bd8a-4ba0-a284-c388b168403c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "surge_10 = np.fmax(surge_10, grade_elev)\n",
    "surge_50 = np.fmax(surge_50, grade_elev)\n",
    "surge_100 = np.fmax(surge_100, grade_elev)\n",
    "surge_500 = np.fmax(surge_500, grade_elev)\n",
    "\n",
    "\n",
    "combined_10 =  np.fmax(combined_10, grade_elev)\n",
    "combined_50 =  np.fmax(combined_50, grade_elev)\n",
    "combined_100 =  np.fmax(combined_100, grade_elev)\n",
    "combined_500 =  np.fmax(combined_500, grade_elev)\n",
    "\n",
    "compound_10 =  np.fmax(compound_10, grade_elev)\n",
    "compound_50 =  np.fmax(compound_50, grade_elev)\n",
    "compound_100 =  np.fmax(compound_100, grade_elev)\n",
    "compound_500 =  np.fmax(compound_500, grade_elev)\n",
    "\n",
    "surge_10 = surge_10.where(~np.isnan(pluvial_10), np.nan)\n",
    "surge_50 = surge_50.where(~np.isnan(pluvial_50), np.nan)\n",
    "surge_100 = surge_100.where(~np.isnan(pluvial_100), np.nan)\n",
    "surge_500 = surge_500.where(~np.isnan(pluvial_500), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0627a35a-3cc8-433e-b091-97c6a67fbe41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calculate differences in the flood surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19351a0b-1cda-4396-a87c-320fa994b149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pluvial_surge_10 = np.fmax(pluvial_10, surge_10)\n",
    "pluvial_surge_riverine_10 = np.fmax(pluvial_surge_10, riverine_10)\n",
    "pluvial_surge_50 = np.fmax(pluvial_50, surge_50)\n",
    "pluvial_surge_riverine_50 = np.fmax(pluvial_surge_50, riverine_50)\n",
    "pluvial_surge_100 = np.fmax(pluvial_100, surge_100)\n",
    "pluvial_surge_riverine_100 = np.fmax(pluvial_surge_100, riverine_100)\n",
    "pluvial_surge_500 = np.fmax(pluvial_500, surge_500)\n",
    "pluvial_surge_riverine_500 = np.fmax(pluvial_surge_500, riverine_500)\n",
    "\n",
    "riverine_surge_10 = np.fmax(riverine_10, surge_10)\n",
    "riverine_surge_50 = np.fmax(riverine_50, surge_50)\n",
    "riverine_surge_100 = np.fmax(riverine_100, surge_100)\n",
    "riverine_surge_500 = np.fmax(riverine_500, surge_500)\n",
    "\n",
    "diff_10 = compound_10 - pluvial_surge_riverine_10\n",
    "diff_50 = compound_50 - pluvial_surge_riverine_50\n",
    "diff_100 = compound_100 - pluvial_surge_riverine_100\n",
    "diff_500 = compound_500 - pluvial_surge_riverine_500\n",
    "\n",
    "diff_10 = diff_10.where(diff_10 >= 0, 0)\n",
    "diff_50 = diff_50.where(diff_50 >= 0, 0)\n",
    "diff_100 = diff_100.where(diff_100 >= 0, 0)\n",
    "diff_500 = diff_500.where(diff_500 >= 0, 0)\n",
    "\n",
    "diff_10_nopluv = compound_10 - riverine_surge_10\n",
    "diff_50_nopluv = compound_50 - riverine_surge_50\n",
    "diff_100_nopluv = compound_100 - riverine_surge_100\n",
    "diff_500_nopluv = compound_500 - riverine_surge_500\n",
    "\n",
    "diff_10_nopluv = diff_10_nopluv.where(diff_10_nopluv >= 0, 0)\n",
    "diff_50_nopluv = diff_50_nopluv.where(diff_50_nopluv >= 0, 0)\n",
    "diff_100_nopluv = diff_100_nopluv.where(diff_100_nopluv >= 0, 0)\n",
    "diff_500_nopluv = diff_500_nopluv.where(diff_500_nopluv >= 0, 0)\n",
    "\n",
    "compound_depth_10 = compound_10 - grade_elev\n",
    "compound_depth_50 = compound_50 - grade_elev\n",
    "compound_depth_100 = compound_100 - grade_elev\n",
    "compound_depth_500 = compound_500 - grade_elev\n",
    "\n",
    "combined_depth_10 = combined_10 - grade_elev\n",
    "combined_depth_50 = combined_50 - grade_elev\n",
    "combined_depth_100 = combined_100 - grade_elev\n",
    "combined_depth_500 = combined_500 - grade_elev\n",
    "\n",
    "#combined_depth_10 = combined_depth_10.where(combined_depth_10 != 0)\n",
    "#combined_depth_50 = combined_depth_10.where(combined_depth_50 != 0)\n",
    "#combined_depth_100 = combined_depth_10.where(combined_depth_100 != 0)\n",
    "#combined_depth_500 = combined_depth_10.where(combined_depth_500 != 0)\n",
    "\n",
    "#combined_depth_10 = combined_depth_10.where((combined_depth_10 >= 0)|(combined_depth_10.isnull()), 0)\n",
    "#combined_depth_50 = combined_depth_50.where((combined_depth_50 >= 0)|(combined_depth_50.isnull()), 0)\n",
    "#combined_depth_100 = combined_depth_100.where((combined_depth_100 >= 0)|(combined_depth_100.isnull()), 0)\n",
    "#combined_depth_500 = combined_depth_500.where((combined_depth_500 >= 0)|(combined_depth_500.isnull()), 0)\n",
    "\n",
    "diff_10_pluv = pluvial_surge_riverine_10 - riverine_surge_10\n",
    "diff_50_pluv = pluvial_surge_riverine_50 - riverine_surge_50\n",
    "diff_100_pluv = pluvial_surge_riverine_100 - riverine_surge_100\n",
    "diff_500_pluv = pluvial_surge_riverine_500 - riverine_surge_500\n",
    "\n",
    "nt_contribution_10 = combined_10 - compound_10\n",
    "nt_contribution_50 = combined_50 - compound_50\n",
    "nt_contribution_100 = combined_100 - compound_100\n",
    "nt_contribution_500 = combined_500 - compound_500\n",
    "\n",
    "nt_contribution_10 = nt_contribution_10.where((nt_contribution_10 >= 0)|(nt_contribution_10.isnull()), 0)\n",
    "nt_contribution_50 = nt_contribution_50.where((nt_contribution_50 >= 0)|(nt_contribution_50.isnull()), 0)\n",
    "nt_contribution_100 = nt_contribution_100.where((nt_contribution_100 >= 0)|(nt_contribution_100.isnull()), 0)\n",
    "nt_contribution_500 = nt_contribution_500.where((nt_contribution_500 >= 0)|(nt_contribution_500.isnull()), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5de7f2f7-cc58-4705-850b-46eefc0045a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check Amite Transect line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9989e6a6-38fd-4386-9589-d7f1758e876c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "amite_line_extended = gpd.read_file(f'{data_dir1}/amite_line_pass_manchac_centered_userpoints.json').to_crs('EPSG:26915')\n",
    "ax = amite_line_extended.plot(figsize=(24, 12))\n",
    "ctx.add_basemap(ax, crs=amite_line_extended.crs, source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e13aa52-b980-4717-9ada-fc7a4a283d5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c923637f-8f69-4500-bca3-d179c412eed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load and Plot Domain Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ed3b501-cd1f-4932-a8f6-6c47e8effada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from rasterio import features\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract non-NaN shapes from the raster\n",
    "shapes = list(\n",
    "    features.shapes(\n",
    "        compound_10, \n",
    "        transform=compound_10.rio.transform(), \n",
    "        mask=~np.isnan(compound_10)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Convert shapes into geometries\n",
    "geometries = []\n",
    "values = []\n",
    "\n",
    "for geom, value in shapes:\n",
    "    geometries.append(shapely.geometry.shape(geom))\n",
    "    values.append(value)\n",
    "\n",
    "# Build GeoDataFrame with proper CRS\n",
    "domain_gdf = gpd.GeoDataFrame(geometry=geometries, crs=compound_10.rio.crs)\n",
    "\n",
    "# Dissolve to merge all polygons into a single shape\n",
    "domain_gdf = domain_gdf.dissolve()\n",
    "\n",
    "# Plot the boundary with formatting\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "domain_gdf.exterior.plot(ax=ax, edgecolor='blue')\n",
    "\n",
    "# Add title and axis labels\n",
    "ax.set_title(\"Compound_10 Domain Boundary\", fontsize=14)\n",
    "ax.set_xlabel(\"Easting (meters)\", fontsize=12)\n",
    "ax.set_ylabel(\"Northing (meters)\", fontsize=12)\n",
    "ax.ticklabel_format(useOffset=False, style='plain')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de4403bd-04dc-44ce-bb08-1dbdcea843f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Comparison to old Data from Purdue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cc47a8d-e1e3-42f2-89f8-bb897e8ca0d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_fig_10_1_rep = combined_fig_10_1.rio.reproject_match(combined_depth_10).rio.clip(domain_gdf.geometry, domain_gdf.crs)\n",
    "combined_fig_50_1_rep = combined_fig_50_1.rio.reproject_match(combined_depth_50).rio.clip(domain_gdf.geometry, domain_gdf.crs)\n",
    "combined_fig_100_1_rep = combined_fig_100_1.rio.reproject_match(combined_depth_100).rio.clip(domain_gdf.geometry, domain_gdf.crs)\n",
    "\n",
    "combined_fig_10_rep = combined_fig_10.rio.reproject_match(combined_depth_10).rio.clip(domain_gdf.geometry, domain_gdf.crs)\n",
    "combined_fig_50_rep = combined_fig_50.rio.reproject_match(combined_depth_50).rio.clip(domain_gdf.geometry, domain_gdf.crs)\n",
    "combined_fig_100_rep = combined_fig_100.rio.reproject_match(combined_depth_100).rio.clip(domain_gdf.geometry, domain_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e388a20f-15e0-4278-8e25-9085979650de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 3, figsize=(18, 36))\n",
    "\n",
    "# First row of plots\n",
    "(combined_fig_50_1_rep - combined_fig_10_1_rep).plot(ax=axes[0, 0], vmin=-5, vmax=5)\n",
    "axes[0, 0].set_title('50_1_rep - 10_1_rep')\n",
    "\n",
    "(combined_fig_100_1_rep - combined_fig_50_1_rep).plot(ax=axes[0, 1], vmin=-5, vmax=5)\n",
    "axes[0, 1].set_title('100_1_rep - 50_1_rep')\n",
    "\n",
    "(combined_fig_100_1_rep - combined_fig_10_1_rep).plot(ax=axes[0, 2], vmin=-5, vmax=5)\n",
    "axes[0, 2].set_title('100_1_rep - 10_1_rep')\n",
    "\n",
    "# Second row of histograms\n",
    "(combined_fig_50_1_rep - combined_fig_10_1_rep).plot.hist(ax=axes[1, 0], bins=50, range=(-5, 5))\n",
    "axes[1, 0].set_title('Histogram: 50_1_rep - 10_1_rep')\n",
    "\n",
    "(combined_fig_100_1_rep - combined_fig_50_1_rep).plot.hist(ax=axes[1, 1], bins=50, range=(-5, 5))\n",
    "axes[1, 1].set_title('Histogram: 100_1_rep - 50_1_rep')\n",
    "\n",
    "(combined_fig_100_1_rep - combined_fig_10_1_rep).plot.hist(ax=axes[1, 2], bins=50, range=(-5, 5))\n",
    "axes[1, 2].set_title('Histogram: 100_1_rep - 10_1_rep')\n",
    "\n",
    "# Third row of plots\n",
    "(combined_fig_50_rep - combined_fig_10_rep).plot(ax=axes[2, 0], vmin=-5, vmax=5)\n",
    "axes[2, 0].set_title('50_rep - 10_rep')\n",
    "\n",
    "(combined_fig_100_rep - combined_fig_50_rep).plot(ax=axes[2, 1], vmin=-5, vmax=5)\n",
    "axes[2, 1].set_title('100_rep - 50_rep')\n",
    "\n",
    "(combined_fig_100_rep - combined_fig_10_rep).plot(ax=axes[2, 2], vmin=-5, vmax=5)\n",
    "axes[2, 2].set_title('100_rep - 10_rep')\n",
    "\n",
    "# Fourth row of histograms\n",
    "(combined_fig_50_rep - combined_fig_10_rep).plot.hist(ax=axes[3, 0], bins=50, range=(-5, 5))\n",
    "axes[3, 0].set_title('Histogram: 50_rep - 10_rep')\n",
    "\n",
    "(combined_fig_100_rep - combined_fig_50_rep).plot.hist(ax=axes[3, 1], bins=50, range=(-5, 5))\n",
    "axes[3, 1].set_title('Histogram: 100_rep - 50_rep')\n",
    "\n",
    "(combined_fig_100_rep - combined_fig_10_rep).plot.hist(ax=axes[3, 2], bins=50, range=(-5, 5))\n",
    "axes[3, 2].set_title('Histogram: 100_rep - 10_rep')\n",
    "\n",
    "# Fifth row of plots\n",
    "(combined_50 - combined_10).plot(ax=axes[4, 0], vmin=-5, vmax=5)\n",
    "axes[4, 0].set_title('combined_50 - combined_10')\n",
    "\n",
    "(combined_100 - combined_50).plot(ax=axes[4, 1], vmin=-5, vmax=5)\n",
    "axes[4, 1].set_title('combined_100 - combined_50')\n",
    "\n",
    "(combined_100 - combined_10).plot(ax=axes[4, 2], vmin=-5, vmax=5)\n",
    "axes[4, 2].set_title('combined_100 - combined_10')\n",
    "\n",
    "# Sixth row of histograms\n",
    "(combined_50 - combined_10).plot.hist(ax=axes[5, 0], bins=50, range=(-5, 5))\n",
    "axes[5, 0].set_title('Histogram: combined_50 - combined_10')\n",
    "\n",
    "(combined_100 - combined_50).plot.hist(ax=axes[5, 1], bins=50, range=(-5, 5))\n",
    "axes[5, 1].set_title('Histogram: combined_100 - combined_50')\n",
    "\n",
    "(combined_100 - combined_10).plot.hist(ax=axes[5, 2], bins=50, range=(-5, 5))\n",
    "axes[5, 2].set_title('Histogram: combined_100 - combined_10')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eb11b86-e1ea-4d87-bea3-b895f41b4ffe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#I couldn't figure out how to fix order issues with the amite line in arcpro, so we do it here\n",
    "fixed_line = ensure_connected_linestring(amite_line.geometry[0])\n",
    "fixed_line_gdf = gpd.GeoDataFrame({'geometry': [fixed_line]}, crs = 'EPSG:26915')\n",
    "\n",
    "\n",
    "distances, values_10 = extract_raster_along_line(diff_10, fixed_line_gdf)\n",
    "distances, values_50 = extract_raster_along_line(diff_50, fixed_line_gdf)\n",
    "distances, values_100 = extract_raster_along_line(diff_100, fixed_line_gdf)\n",
    "distances, values_500 = extract_raster_along_line(diff_500, fixed_line_gdf)\n",
    "\n",
    "distances, compound_10_values = extract_raster_along_line(compound_10, fixed_line_gdf)\n",
    "distances, compound_50_values = extract_raster_along_line(compound_50, fixed_line_gdf)\n",
    "distances, compound_100_values = extract_raster_along_line(compound_100, fixed_line_gdf)\n",
    "distances, compound_500_values = extract_raster_along_line(compound_500, fixed_line_gdf)\n",
    "\n",
    "distances, pluvial_surge_riverine_10_values = extract_raster_along_line(pluvial_surge_riverine_10, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_50_values = extract_raster_along_line(pluvial_surge_riverine_50, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_100_values = extract_raster_along_line(pluvial_surge_riverine_100, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_500_values = extract_raster_along_line(pluvial_surge_riverine_500, fixed_line_gdf)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7.5, 12))  # academic width ~7.5 inches\n",
    "\n",
    "gs = fig.add_gridspec(5, 2)\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 0])\n",
    "ax3 = fig.add_subplot(gs[3, 0])\n",
    "ax4 = fig.add_subplot(gs[4, 0])\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax7 = fig.add_subplot(gs[3, 1])\n",
    "ax8 = fig.add_subplot(gs[4, 1])\n",
    "ax9 = fig.add_subplot(gs[0, :])  # overview map\n",
    "\n",
    "# Plot lines - Left column: solid (Compound), dashed (Max of 3)\n",
    "ax1.plot(distances/1000, compound_10_values, linestyle='-', color='black')\n",
    "ax1.plot(distances/1000, pluvial_surge_riverine_10_values, linestyle='--', color='black')\n",
    "ax2.plot(distances/1000, compound_50_values, linestyle='-', color='black')\n",
    "ax2.plot(distances/1000, pluvial_surge_riverine_50_values, linestyle='--', color='black')\n",
    "ax3.plot(distances/1000, compound_100_values, linestyle='-', color='black')\n",
    "ax3.plot(distances/1000, pluvial_surge_riverine_100_values, linestyle='--', color='black')\n",
    "ax4.plot(distances/1000, compound_500_values, linestyle='-', color='black')\n",
    "ax4.plot(distances/1000, pluvial_surge_riverine_500_values, linestyle='--', color='black')\n",
    "\n",
    "# Right column: Difference plots (black)\n",
    "ax5.plot(distances/1000, values_10, color='black')\n",
    "ax6.plot(distances/1000, values_50, color='black')\n",
    "ax7.plot(distances/1000, values_100, color='black')\n",
    "ax8.plot(distances/1000, values_500, color='black')\n",
    "\n",
    "# Labels\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_ylabel('WSE (ft)', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "\n",
    "for ax in [ax5, ax6, ax7, ax8]:\n",
    "    ax.set_ylabel('WSE Difference (ft)', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "\n",
    "# Titles\n",
    "ax1.set_title('10-year', fontsize=11)\n",
    "ax2.set_title('50-year', fontsize=11)\n",
    "ax3.set_title('100-year', fontsize=11)\n",
    "ax4.set_title('500-year', fontsize=11)\n",
    "ax5.set_title('10-year', fontsize=11)\n",
    "ax6.set_title('50-year', fontsize=11)\n",
    "ax7.set_title('100-year', fontsize=11)\n",
    "ax8.set_title('500-year', fontsize=11)\n",
    "\n",
    "#fig.suptitle('Difference between compound flood depths and max of 3 individual drivers along Amite transect', fontsize=11)\n",
    "\n",
    "# Top map\n",
    "ax9.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "fixed_line_gdf.plot(ax=ax9)\n",
    "domain_gdf.exterior.plot(ax=ax9)\n",
    "ctx.add_basemap(ax9, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "# Custom legend for left column\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig.subplots_adjust(top=0.96, hspace=0.6, wspace=0.3)\n",
    "\n",
    "\n",
    "# Custom line styles\n",
    "legend_elements_left = [\n",
    "    Line2D([0], [0], linestyle='-', color='black', label='Compounded Flood Elevation'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label='Max of Pluvial, Fluvial, and Coastal Drivers')\n",
    "]\n",
    "\n",
    "from matplotlib.patches import Patch  # add this import at the top if not already present\n",
    "\n",
    "legend_elements_right = [\n",
    "    Patch(facecolor='none', edgecolor='none', label='Flood Depth Difference of Compound Flood\\nand Max of Pluvial, Fluvial, and Coastal Drivers')\n",
    "]\n",
    "\n",
    "\n",
    "#Axes for placing column legends\n",
    "ax_legend_left = fig.add_axes([0.07, 0.79, 0.42, 0.05])   # [left, bottom, width, height]\n",
    "ax_legend_right = fig.add_axes([0.52, 0.79, 0.42, 0.05])\n",
    "\n",
    "\n",
    "# Turn off everything for dummy axes\n",
    "for ax in [ax_legend_left, ax_legend_right]:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Left column legend\n",
    "ax_legend_left.legend(\n",
    "    handles=legend_elements_left,\n",
    "    loc='center',\n",
    "    fontsize=10,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# Right column legend\n",
    "ax_legend_right.legend(\n",
    "    handles=legend_elements_right,\n",
    "    loc='center',\n",
    "    fontsize=10,\n",
    "    frameon=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ed81c5-7c28-41db-9e3e-e66c76f1c1cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figure 7\n",
    "In both feet and meters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff4e8dd5-c8e7-49c2-8e0a-636257a40f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fixed_line = ensure_connected_linestring(amite_line.geometry[0])\n",
    "fixed_line_gdf = gpd.GeoDataFrame({'geometry': [fixed_line]}, crs = 'EPSG:26915')\n",
    "\n",
    "\n",
    "distances, values_10 = extract_raster_along_line(diff_10, fixed_line_gdf)\n",
    "distances, values_50 = extract_raster_along_line(diff_50, fixed_line_gdf)\n",
    "distances, values_100 = extract_raster_along_line(diff_100, fixed_line_gdf)\n",
    "distances, values_500 = extract_raster_along_line(diff_500, fixed_line_gdf)\n",
    "\n",
    "distances, compound_10_values = extract_raster_along_line(compound_10, fixed_line_gdf)\n",
    "distances, compound_50_values = extract_raster_along_line(compound_50, fixed_line_gdf)\n",
    "distances, compound_100_values = extract_raster_along_line(compound_100, fixed_line_gdf)\n",
    "distances, compound_500_values = extract_raster_along_line(compound_500, fixed_line_gdf)\n",
    "\n",
    "distances, pluvial_surge_riverine_10_values = extract_raster_along_line(pluvial_surge_riverine_10, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_50_values = extract_raster_along_line(pluvial_surge_riverine_50, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_100_values = extract_raster_along_line(pluvial_surge_riverine_100, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_500_values = extract_raster_along_line(pluvial_surge_riverine_500, fixed_line_gdf)\n",
    "\n",
    "# ---------- x in km ----------\n",
    "x_km = distances / 1000.0\n",
    "tick_labels = [0, 20, 40, 60, 80, 100, 120]\n",
    "\n",
    "# ---------- figure + axes ----------\n",
    "fig = plt.figure(figsize=(7.5, 12))\n",
    "gs = fig.add_gridspec(5, 2)\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 0])\n",
    "ax3 = fig.add_subplot(gs[3, 0])\n",
    "ax4 = fig.add_subplot(gs[4, 0])\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax7 = fig.add_subplot(gs[3, 1])\n",
    "ax8 = fig.add_subplot(gs[4, 1])\n",
    "#ax9 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "# ---------- left curves ----------\n",
    "ax1.plot(x_km, compound_10_values,  '-',  color='black')\n",
    "ax1.plot(x_km, pluvial_surge_riverine_10_values,  '--', color='black')\n",
    "\n",
    "ax2.plot(x_km, compound_50_values,  '-',  color='black')\n",
    "ax2.plot(x_km, pluvial_surge_riverine_50_values,  '--', color='black')\n",
    "\n",
    "ax3.plot(x_km, compound_100_values, '-',  color='black')\n",
    "ax3.plot(x_km, pluvial_surge_riverine_100_values, '--', color='black')\n",
    "\n",
    "ax4.plot(x_km, compound_500_values, '-',  color='black')\n",
    "ax4.plot(x_km, pluvial_surge_riverine_500_values, '--', color='black')\n",
    "\n",
    "# ---------- right curves ----------\n",
    "ax5.plot(x_km, values_10,   color='black')\n",
    "ax6.plot(x_km, values_50,   color='black')\n",
    "ax7.plot(x_km, values_100,  color='black')\n",
    "ax8.plot(x_km, values_500,  color='black')\n",
    "\n",
    "# ---------- CFTZ (rows 12 'between'; rows 34 'to_right') ----------\n",
    "rows = [\n",
    "    (ax1, ax5, values_10,  \"between\"),   # 10-year\n",
    "    (ax2, ax6, values_50,  \"between\"),   # 50-year\n",
    "    (ax3, ax7, values_100, \"between\"),  # 100-year\n",
    "    (ax4, ax8, values_500, \"between\"),  # 500-year\n",
    "]\n",
    "\n",
    "CROSSING_LEVEL =.33\n",
    "for L_ax, R_ax, diff_vals, mode in rows:\n",
    "    xs = all_level_crossings(x_km, diff_vals, level=CROSSING_LEVEL )\n",
    "    xs= group_and_average(xs)\n",
    "    print(xs)\n",
    "    # choose outermost pair; if less than 2 crossings, fall back to a tiny span\n",
    "    if len(xs) <= 2:\n",
    "        xL, xR = xs[0], xs[-1]\n",
    "    elif len(xs) == 1:\n",
    "        xL, xR = xs[0], xs[0] + max(0.01, 0.01 * (x_km[-1] - x_km[0]))  # small visible span\n",
    "    elif len(xs) > 2:\n",
    "        xL, xL1, xR, xR1 = xs[0], xs[-1], xs[1], xs[-2]\n",
    "    else:\n",
    "        # if no crossing, skip verticals/dotted line\n",
    "        continue\n",
    "    if len(xs) <= 2:\n",
    "        draw_cftz(L_ax, R_ax, xL, xR, mode=mode, label=\"CFTZ\")\n",
    "    else:\n",
    "        draw_cftz(L_ax, R_ax, xL, xR, mode=mode, label=\"CFTZ\")\n",
    "        draw_cftz(L_ax, R_ax, xL1, xR1, mode=mode, label=\"CFTZ\")\n",
    "\n",
    "# ---------- labels/ticks ----------\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_ylabel('WSE, ft NAVD88', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "    ax.set_xticks(tick_labels)\n",
    "    ax.set_xticklabels([str(t) for t in tick_labels])\n",
    "    set_integer_yticks(ax)\n",
    "\n",
    "for ax in [ax5, ax6, ax7, ax8]:\n",
    "    ax.set_ylabel('WSE Difference, ft', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "    ax.set_xticks(tick_labels)\n",
    "    ax.set_xticklabels([str(t) for t in tick_labels])\n",
    "    set_integer_yticks(ax)\n",
    "\n",
    "# ---------- titles ----------\n",
    "ax1.set_title('10-year',  fontsize=11); ax5.set_title('10-year',  fontsize=11)\n",
    "ax2.set_title('50-year',  fontsize=11); ax6.set_title('50-year',  fontsize=11)\n",
    "ax3.set_title('100-year', fontsize=11); ax7.set_title('100-year', fontsize=11)\n",
    "ax4.set_title('500-year', fontsize=11); ax8.set_title('500-year', fontsize=11)\n",
    "\n",
    "# ---------- overview map ----------\n",
    "\n",
    "#ax9.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "#                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "#fixed_line_gdf.plot(ax=ax9)\n",
    "#domain_gdf.exterior.plot(ax=ax9)\n",
    "#ctx.add_basemap(ax9, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "# ---------- legends ----------\n",
    "fig.subplots_adjust(top=0.96, hspace=0.6, wspace=0.35)\n",
    "legend_elements_left = [\n",
    "    Line2D([0], [0], linestyle='-',  color='black', label='Compounded Flood Elevation'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label='Max of Pluvial, Fluvial, and Coastal Floods')\n",
    "]\n",
    "legend_elements_right = [\n",
    "    Patch(facecolor='none', edgecolor='none')\n",
    "          #label='WSE Difference')\n",
    "]\n",
    "ax_legend_left  = fig.add_axes([0.07, 0.02, 0.42, 0.05])\n",
    "ax_legend_right = fig.add_axes([0.52, 0.79, 0.42, 0.05])\n",
    "for ax in (ax_legend_left, ax_legend_right):\n",
    "    ax.axis('off')\n",
    "ax_legend_left.legend(handles=legend_elements_left,  loc='lower center', fontsize=10, frameon=False)\n",
    "ax_legend_right.legend(handles=legend_elements_right, loc='center', fontsize=10, frameon=False)\n",
    "\n",
    "#fig.legend(handles=legend_elements_left, loc='lower center', fontsize=11, frameon=False, ncol=2, bbox_to_anchor=(0.5, 0.03))\n",
    "\n",
    "plt.savefig(\"transects.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21eecaa2-fb03-4625-b987-f5ff8f614561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- x in km ----------\n",
    "x_km = distances / 1000.0\n",
    "tick_labels = [0, 20, 40, 60, 80, 100, 120]\n",
    "\n",
    "# ---------- figure + axes ----------\n",
    "fig = plt.figure(figsize=(7.5, 12))\n",
    "gs = fig.add_gridspec(5, 2)\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 0])\n",
    "ax3 = fig.add_subplot(gs[3, 0])\n",
    "ax4 = fig.add_subplot(gs[4, 0])\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax7 = fig.add_subplot(gs[3, 1])\n",
    "ax8 = fig.add_subplot(gs[4, 1])\n",
    "#ax9 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "# ---------- left curves ----------\n",
    "ax1.plot(x_km, compound_10_values*0.3048,  '-',  color='black')\n",
    "ax1.plot(x_km, pluvial_surge_riverine_10_values*0.3048,  '--', color='black')\n",
    "\n",
    "ax2.plot(x_km, compound_50_values*0.3048,  '-',  color='black')\n",
    "ax2.plot(x_km, pluvial_surge_riverine_50_values*0.3048,  '--', color='black')\n",
    "\n",
    "ax3.plot(x_km, compound_100_values*0.3048, '-',  color='black')\n",
    "ax3.plot(x_km, pluvial_surge_riverine_100_values*0.3048, '--', color='black')\n",
    "\n",
    "ax4.plot(x_km, compound_500_values*0.3048, '-',  color='black')\n",
    "ax4.plot(x_km, pluvial_surge_riverine_500_values*0.3048, '--', color='black')\n",
    "\n",
    "# ---------- right curves ----------\n",
    "ax5.plot(x_km, values_10*0.3048,   color='black')\n",
    "ax6.plot(x_km, values_50*0.3048,   color='black')\n",
    "ax7.plot(x_km, values_100*0.3048,  color='black')\n",
    "ax8.plot(x_km, values_500*0.3048,  color='black')\n",
    "\n",
    "# ---------- CFTZ (rows 12 'between'; rows 34 'to_right') ----------\n",
    "rows = [\n",
    "    (ax1, ax5, values_10*0.3048,  \"between\"),   # 10-year\n",
    "    (ax2, ax6, values_50*0.3048,  \"between\"),   # 50-year\n",
    "    (ax3, ax7, values_100*0.3048, \"between\"),  # 100-year\n",
    "    (ax4, ax8, values_500*0.3048, \"between\"),  # 500-year\n",
    "]\n",
    "\n",
    "CROSSING_LEVEL =.33*0.3048\n",
    "for L_ax, R_ax, diff_vals, mode in rows:\n",
    "    xs = all_level_crossings(x_km, diff_vals, level=CROSSING_LEVEL )\n",
    "    xs= group_and_average(xs)\n",
    "    print(xs)\n",
    "    # choose outermost pair; if less than 2 crossings, fall back to a tiny span\n",
    "    if len(xs) <= 2:\n",
    "        xL, xR = xs[0], xs[-1]\n",
    "    elif len(xs) == 1:\n",
    "        xL, xR = xs[0], xs[0] + max(0.01, 0.01 * (x_km[-1] - x_km[0]))  # small visible span\n",
    "    elif len(xs) > 2:\n",
    "        xL, xL1, xR, xR1 = xs[0], xs[-1], xs[1], xs[-2]\n",
    "    else:\n",
    "        # if no crossing, skip verticals/dotted line\n",
    "        continue\n",
    "    if len(xs) <= 2:\n",
    "        draw_cftz(L_ax, R_ax, xL, xR, mode=mode, label=\"CFTZ\")\n",
    "    else:\n",
    "        draw_cftz(L_ax, R_ax, xL, xR, mode=mode, label=\"CFTZ\")\n",
    "        draw_cftz(L_ax, R_ax, xL1, xR1, mode=mode, label=\"CFTZ\")\n",
    "\n",
    "# ---------- labels/ticks ----------\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_ylabel('WSE, m NAVD88', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "    ax.set_xticks(tick_labels)\n",
    "    ax.set_xticklabels([str(t) for t in tick_labels])\n",
    "    #set_integer_yticks(ax)\n",
    "\n",
    "for ax in [ax5, ax6, ax7, ax8]:\n",
    "    ax.set_ylabel('WSE Difference, m', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "    ax.set_xticks(tick_labels)\n",
    "    ax.set_xticklabels([str(t) for t in tick_labels])\n",
    "    #set_integer_yticks(ax)\n",
    "\n",
    "# ---------- titles ----------\n",
    "ax1.set_title('10-year',  fontsize=11); ax5.set_title('10-year',  fontsize=11)\n",
    "ax2.set_title('50-year',  fontsize=11); ax6.set_title('50-year',  fontsize=11)\n",
    "ax3.set_title('100-year', fontsize=11); ax7.set_title('100-year', fontsize=11)\n",
    "ax4.set_title('500-year', fontsize=11); ax8.set_title('500-year', fontsize=11)\n",
    "\n",
    "# ---------- overview map ----------\n",
    "#ax9.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "#                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "#fixed_line_gdf.plot(ax=ax9)\n",
    "#domain_gdf.exterior.plot(ax=ax9)\n",
    "#ctx.add_basemap(ax9, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "# ---------- legends ----------\n",
    "fig.subplots_adjust(top=0.96, hspace=0.6, wspace=0.3)\n",
    "legend_elements_left = [\n",
    "    Line2D([0], [0], linestyle='-',  color='black', label='Compounded Flood Elevation'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label='Max of Pluvial, Fluvial, and Coastal Floods')\n",
    "]\n",
    "legend_elements_right = [\n",
    "    Patch(facecolor='none', edgecolor='none')\n",
    "          #label='WSE Difference')\n",
    "]\n",
    "ax_legend_left  = fig.add_axes([0.07, 0.02, 0.42, 0.05])\n",
    "ax_legend_right = fig.add_axes([0.52, 0.79, 0.42, 0.05])\n",
    "for ax in (ax_legend_left, ax_legend_right):\n",
    "    ax.axis('off')\n",
    "ax_legend_left.legend(handles=legend_elements_left,  loc='lower center', fontsize=10, frameon=False)\n",
    "ax_legend_right.legend(handles=legend_elements_right, loc='center', fontsize=10, frameon=False)\n",
    "\n",
    "#fig.legend(handles=legend_elements_left, loc='lower center', fontsize=11, frameon=False, ncol=2, bbox_to_anchor=(0.5, 0.03))\n",
    "\n",
    "plt.savefig(\"transects.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccf380d2-fab6-49f8-8be2-4e261daa65fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transition Zone area for the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ac4527-7f18-4e80-b6cc-af4a75b3ef17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diff10_area = diff_10 > difference_threshold\n",
    "diff50_area_increase_only = (diff_50 > difference_threshold)|(diff_10 > difference_threshold)\n",
    "diff100_area_increase_only = (diff_100 > difference_threshold)|(diff_50 > difference_threshold)|(diff_10 > difference_threshold)\n",
    "diff500_area_increase_only = (diff_500 > difference_threshold)|(diff_100 > difference_threshold)|(diff_50 > difference_threshold)|(diff_10 > difference_threshold)\n",
    "\n",
    "diff10_area = diff_10 > difference_threshold\n",
    "diff50_area = (diff_50 > difference_threshold)\n",
    "diff100_area = (diff_100 > difference_threshold)\n",
    "diff500_area = (diff_500 > difference_threshold)\n",
    "\n",
    "#one of the dimensions is negative for unclear reasons, probably to do with the ordering of cells\n",
    "cell_area = np.abs(diff10_area.rio.resolution()[0] * diff10_area.rio.resolution()[1])\n",
    "\n",
    "diff10_area_val = (diff10_area.sum() * cell_area).values/10**6\n",
    "diff50_area_val = (diff50_area.sum() * cell_area).values/10**6\n",
    "diff100_area_val = (diff100_area.sum() * cell_area).values/10**6\n",
    "diff500_area_val = (diff500_area.sum() * cell_area).values/10**6\n",
    "\n",
    "\n",
    "diff10_area_increasing_val = (diff10_area.sum() * cell_area).values/10**6\n",
    "diff50_area_increasing_val = (diff50_area_increase_only.sum() * cell_area).values/10**6\n",
    "diff100_area_increasing_val = (diff100_area_increase_only.sum() * cell_area).values/10**6\n",
    "diff500_area_increasing_val = (diff500_area_increase_only.sum() * cell_area).values/10**6\n",
    "\n",
    "\n",
    "print(f'the area of the transition zone at return periods of 10, 50, 100, and 500 years are {diff10_area_val}, {diff50_area_val}, {diff100_area_val}, and {diff500_area_val} square km respectively')\n",
    "\n",
    "print(f'the area considering the area of the TZ only increses with RP of the 10, 50, 100, and 500 years are {diff10_area_increasing_val}, {diff50_area_increasing_val}, {diff100_area_increasing_val}, and {diff500_area_increasing_val} square km respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dbb159b-6879-47fd-9d4a-557f4c1573da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figure 6\n",
    "In both feet and meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67f8ad3-3255-46a4-9c61-9ada8931be38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------- settings ----------------\n",
    "# Convert from feet to meters (multiply by 0.3048)\n",
    "LOW_CUT = 0.33 * 0.3048    # treat near-zero background as transparent (but don't create gaps)\n",
    "HIGH_DROP = 3.5 * 0.3048    # drop the yellow-line outliers\n",
    "VMIN, VMAX = 0, 2.25 * 0.3048\n",
    "RASTER_CRS = \"EPSG:26915\"\n",
    "\n",
    "# colormap + normalizer\n",
    "blues = plt.cm.Blues\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Blues_dark', blues(np.linspace(0.3, 1.0, 256))\n",
    ")\n",
    "\n",
    "# make values below LOW_CUT fully transparent (for pretty basemap)\n",
    "cmap.set_under((0, 0, 0, 0))\n",
    "norm = Normalize(vmin=LOW_CUT, vmax=VMAX)\n",
    "\n",
    "def prep(da):\n",
    "    # Convert to meters and keep finite values, drop the artifact band, and make near-zeros transparent\n",
    "    da_m = da * 0.3048  # convert feet to meters\n",
    "    da2 = da_m.where(np.isfinite(da_m) & (da_m < HIGH_DROP))\n",
    "    da2 = da2.where(da2 >= LOW_CUT)  # below vmin -> transparent because of set_under\n",
    "    return da2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9.6, 7.6), dpi=120)\n",
    "\n",
    "# -------- plot panels (no gaps, no yellow band) --------\n",
    "prep(diff_10 ).plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "prep(diff_50 ).plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "prep(diff_100).plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "prep(diff_500).plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "# -------- basemap + cosmetics --------\n",
    "for a, title, area_val in zip(ax.flat, [\"10-year\", \"50-year\", \"100-year\", \"500-year\"],\n",
    "                              [diff10_area_val, diff50_area_val, diff100_area_val, diff500_area_val]):\n",
    "    ctx.add_basemap(a, crs=RASTER_CRS, source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect(\"equal\")\n",
    "    a.set_title(title, fontsize=12, pad=6)\n",
    "    a.set_xlabel(\"\"); a.set_ylabel(\"\")\n",
    "    a.tick_params(axis='both', which='both',\n",
    "                  bottom=False, top=False, right=False, left=False,\n",
    "                  labelbottom=False, labelleft=False)\n",
    "    a.text(0.05, 0.05, f\"CFTZ Area:\\n{round(area_val)} km\", transform=a.transAxes, \n",
    "           fontsize=8, color='black', ha='left')\n",
    "\n",
    "# overlay the Amite transect with 0/20/40/60/80 km marks on EACH panel\n",
    "for a in ax.flat:\n",
    "    overlay_transect(a, fixed_line, km_ticks=(0,20,40,60,80,100,115),\n",
    "                     line_lw=.5, dot_size=15, label_fontsize=7,\n",
    "                     ensure_north_start=False, label_position='right')\n",
    "\n",
    "# -------- shared colorbar --------\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.70])   # [left, bottom, width, height]\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Difference in WSE, m\", fontsize=12)\n",
    "\n",
    "# Create ticks rounded to nearest tenth\n",
    "ticks = np.linspace(LOW_CUT, VMAX, 9)\n",
    "cb.set_ticks(ticks)\n",
    "cb.set_ticklabels([f\"{t:.1f}\" for t in ticks])  # Format to 1 decimal place\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.92, bottom=0.08, wspace=0.08, hspace=0.10)\n",
    "plt.savefig(\"transition_panels.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e8993e-8146-4ecc-b3e1-4ec5b15510a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- settings ----------------\n",
    "LOW_CUT = 0.33    # treat near-zero background as transparent (but don't create gaps)\n",
    "HIGH_DROP = 3.5    # drop the yellow-line outliers\n",
    "VMIN, VMAX = 0, 2.25\n",
    "RASTER_CRS = \"EPSG:26915\"\n",
    "\n",
    "# colormap + normalizer\n",
    "blues = plt.cm.Blues\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Blues_dark', blues(np.linspace(0.3, 1.0, 256))\n",
    ")\n",
    "\n",
    "# make values below LOW_CUT fully transparent (for pretty basemap)\n",
    "cmap.set_under((0, 0, 0, 0))\n",
    "norm = Normalize(vmin=LOW_CUT, vmax=VMAX)\n",
    "\n",
    "def prep(da):\n",
    "    # keep finite values, drop the artifact band, and make near-zeros transparent\n",
    "    da2 = da.where(np.isfinite(da) & (da < HIGH_DROP))\n",
    "    da2 = da2.where(da2 >= LOW_CUT)  # below vmin -> transparent because of set_under\n",
    "    return da2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9.6, 7.6), dpi=120)\n",
    "\n",
    "# -------- plot panels (no gaps, no yellow band) --------\n",
    "prep(diff_10 ).plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "prep(diff_50 ).plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "prep(diff_100).plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "prep(diff_500).plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "# -------- basemap + cosmetics --------\n",
    "for a, title, area_val in zip(ax.flat, [\"10-year\", \"50-year\", \"100-year\", \"500-year\"],\n",
    "                              [diff10_area_val, diff50_area_val, diff100_area_val, diff500_area_val]):\n",
    "    ctx.add_basemap(a, crs=RASTER_CRS, source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect(\"equal\")\n",
    "    a.set_title(title, fontsize=12, pad=6)\n",
    "    a.set_xlabel(\"\"); a.set_ylabel(\"\")\n",
    "    a.tick_params(axis='both', which='both',\n",
    "                  bottom=False, top=False, right=False, left=False,\n",
    "                  labelbottom=False, labelleft=False)\n",
    "    a.text(0.05, 0.05, f\"CFTZ Area:\\n{round(area_val)} km\", transform=a.transAxes, \n",
    "           fontsize=8, color='black', ha='left')\n",
    "\n",
    "# overlay the Amite transect with 0/20/40/60/80 km marks on EACH panel\n",
    "for a in ax.flat:\n",
    "    overlay_transect(a, fixed_line, km_ticks=(0,20,40,60,80,100,115),\n",
    "                     line_lw=.5, dot_size=15, label_fontsize=7,\n",
    "                     ensure_north_start=False, label_position='right')\n",
    "\n",
    "# -------- shared colorbar --------\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.70])   # [left, bottom, width, height]\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Difference in WSE (ft)\", fontsize=12)\n",
    "ticks = np.linspace(LOW_CUT, VMAX, 9)\n",
    "cb.set_ticks(ticks)\n",
    "cb.set_ticklabels([f\"{t:g}\" for t in ticks])\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.92, bottom=0.08, wspace=0.08, hspace=0.10)\n",
    "plt.savefig(\"transition_panels.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cc2a00c-0e27-43d7-aed6-00effaa54fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "arr = (prep(diff_500)/pluvial_surge_riverine_50*100)\n",
    "print(np.nanmin(arr.values), np.nanmax(arr.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a16dd57-201a-436e-828e-d24797d48cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "arr = (prep(diff_500)/pluvial_surge_riverine_500*100)\n",
    "print(np.nanmin(arr.values), np.nanmax(arr.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b23dd5d-0341-40c7-b511-19e5ffb0f102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7240a3eb-ad9b-492f-9a9e-cfff752621b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------- settings ----------------\n",
    "LOW_CUT = 0.33     # treat near-zero background as transparent (but don't create gaps)\n",
    "HIGH_DROP = 3.5    # drop the yellow-line outliers\n",
    "VMIN, VMAX = 0, 2.25\n",
    "RASTER_CRS = \"EPSG:26915\"\n",
    "\n",
    "# colormap + normalizer\n",
    "cmap = cm.get_cmap(\"cividis\").copy()\n",
    "\n",
    "# make values below LOW_CUT fully transparent (for pretty basemap)\n",
    "cmap.set_under((0, 0, 0, 0))\n",
    "norm = Normalize(vmin=0, vmax=50)\n",
    "\n",
    "def prep(da):\n",
    "    # keep finite values, drop the artifact band, and make near-zeros transparent\n",
    "    da2 = da.where(np.isfinite(da) & (da < HIGH_DROP))\n",
    "    da2 = da2.where(da2 >= LOW_CUT)  # below vmin -> transparent because of set_under\n",
    "    return da2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9.6, 7.6), dpi=120)\n",
    "\n",
    "# -------- plot panels (no gaps, no yellow band) --------\n",
    "(prep(diff_10 )/pluvial_surge_riverine_10*100).plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "(prep(diff_50 )/pluvial_surge_riverine_50*100).plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "(prep(diff_100)/pluvial_surge_riverine_100*100).plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "(prep(diff_500)/pluvial_surge_riverine_500*100).plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "# -------- basemap + cosmetics --------\n",
    "for a, title in zip(ax.flat, [\"10-year\",\"50-year\",\"100-year\",\"500-year\"]):\n",
    "    ctx.add_basemap(a, crs=RASTER_CRS, source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect(\"equal\")\n",
    "    a.set_title(title, fontsize=12, pad=6)\n",
    "    a.set_xlabel(\"\"); a.set_ylabel(\"\")\n",
    "    a.tick_params(axis='both', which='both',\n",
    "                  bottom=False, top=False, right=False, left=False,\n",
    "                  labelbottom=False, labelleft=False)\n",
    "\n",
    "# overlay the Amite transect with 0/20/40/60/80 km marks on EACH panel\n",
    "# (set ensure_north_start=True if you want \"0\" forced to the top/north)\n",
    "for a in ax.flat:\n",
    "    overlay_transect(a, fixed_line, km_ticks=(0,20,40,60,80,100,115),\n",
    "                     line_lw=.75, dot_size=15, label_fontsize=7,\n",
    "                     ensure_north_start=False, label_position='right')\n",
    "\n",
    "# -------- shared colorbar --------\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.70])   # [left, bottom, width, height]\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Percent increase\", fontsize=12)\n",
    "# nice ticks starting at 0 even though vmin is LOW_CUT\n",
    "ticks = np.linspace(0, 50, 5)\n",
    "cb.set_ticks(ticks)\n",
    "cb.set_ticklabels([f\"{t:g}\" for t in ticks])\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.92, bottom=0.08, wspace=0.08, hspace=0.10)\n",
    "plt.savefig(\"transition_percent_panels.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4b69ef5-6871-4ab4-a072-e40611c870d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Outlines of CFTZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a666812a-0b05-4ed9-98ed-9d8b06457e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- cumulative 0.54.0 ft transition outlines (outliers removed) + QA plot ---\n",
    "\n",
    "#I have to reimport the shapely Polygon functionality b/c it conflicts with \"from matplotlib.patches import Patch, Polygon\"\n",
    "from shapely.geometry import LineString, Point, MultiLineString, Polygon\n",
    "# ---- build compounded masks with outlier cap ----\n",
    "m10  = make_band_mask(diff_10,  THRESH_MIN, THRESH_MAX)\n",
    "mc50  = compound_masks(m10,  make_band_mask(diff_50,  THRESH_MIN, THRESH_MAX))\n",
    "mc100 = compound_masks(mc50,  make_band_mask(diff_100, THRESH_MIN, THRESH_MAX))\n",
    "mc500 = compound_masks(mc100, make_band_mask(diff_500, THRESH_MIN, THRESH_MAX))\n",
    "m50  = make_band_mask(diff_50,  THRESH_MIN, THRESH_MAX)\n",
    "m100 = make_band_mask(diff_100,  THRESH_MIN, THRESH_MAX)\n",
    "m500 = make_band_mask(diff_500,  THRESH_MIN, THRESH_MAX)\n",
    "\n",
    "# ---- outlines ----\n",
    "g10  = mask_to_outline_gdf(m10,  diff_10)\n",
    "g50  = mask_to_outline_gdf(m50,  diff_50)\n",
    "g100 = mask_to_outline_gdf(m100, diff_100)\n",
    "g500 = mask_to_outline_gdf(m500, diff_500)\n",
    "\n",
    "gc = mask_to_outline_gdf(mc500, diff_500)\n",
    "\n",
    "print(\"10-yr outline empty?\",  g10.empty)\n",
    "print(\"50-yr outline empty?\",  g50.empty)\n",
    "print(\"100-yr outline empty?\", g100.empty)\n",
    "print(\"500-yr outline empty?\", g500.empty)\n",
    "\n",
    "# ---- save for reuse ----\n",
    "save_geojson(g10,  \"../data/CFTZ_outline_10_yr.geojson\")\n",
    "save_geojson(g50,  \"../data/CFTZ_outline_50_yr.geojson\")\n",
    "save_geojson(g100, \"../data/CFTZ_outline_100_yr.geojson\")\n",
    "save_geojson(g500, \"../data/CFTZ_outline_500_yr.geojson\")\n",
    "\n",
    "# ---- quick QA plot ----\n",
    "def qa_outline(ax, g, title):\n",
    "    if g.empty:\n",
    "        ax.set_title(title)\n",
    "        ax.text(0.5, 0.5, \"EMPTY\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.set_axis_off()\n",
    "        return\n",
    "    g3857 = g.to_crs(3857)\n",
    "    minx, miny, maxx, maxy = g3857.total_bounds\n",
    "    pad_x, pad_y = (maxx - minx)*0.05, (maxy - miny)*0.05\n",
    "    ax.set_xlim(minx - pad_x, maxx + pad_x); ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)  # Web Mercator\n",
    "    g3857.plot(ax=ax, color=\"royalblue\", linewidth=2.0, zorder=5)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(11, 7.2))\n",
    "qa_outline(axes[0,0], g10,  \"10-year\")\n",
    "qa_outline(axes[0,1], g50,  \"50-year\")\n",
    "qa_outline(axes[1,0], g100, \"100-year\")\n",
    "qa_outline(axes[1,1], g500, \"500-year\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7b4334e-897d-4e1e-bd70-ee5ca2bbaab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Bilskie Paper Comparison Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b4ed4b-6292-4769-8ac1-ed00c69ef49c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bilskie_path = \"../data/flood_zones_FeaturesToJSON.geojson\"\n",
    "zones = gpd.read_file(bilskie_path)\n",
    "\n",
    "# match CRS with rasters\n",
    "if zones.crs is None:\n",
    "    zones.set_crs(3857, inplace=True)\n",
    "elif zones.crs != 3857:\n",
    "    zones = zones.to_crs(3857)\n",
    "\n",
    "transition_gdf = get_transition_polys(zones)\n",
    "\n",
    "\n",
    "transition_gdf_simplified = simplify_transition_gdf(transition_gdf)\n",
    "\n",
    "transition_gdf_simplified26915=transition_gdf_simplified.to_crs(26915)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bae1ee0a-1a92-4b9c-b76c-3b73924a6e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calculate Areas of CFTZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19ffa8da-a246-4412-bb4a-9e020a3c5405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# If the lines form a closed polygon\n",
    "merged_lines = linemerge(gc.to_crs(26915).geometry.tolist())\n",
    "polygons = list(polygonize([merged_lines]))\n",
    "if polygons:\n",
    "    total_area_km2 = sum(poly.area for poly in polygons) / 1e6\n",
    "    print(f\"Total polygon area: {total_area_km2:.2f} km\")\n",
    "\n",
    "# If the lines form a closed polygon\n",
    "merged_lines = linemerge(transition_gdf_simplified.to_crs(26915).geometry.tolist())\n",
    "polygons = list(polygonize([merged_lines]))\n",
    "if polygons:\n",
    "    total_area_km2 = sum(poly.area for poly in polygons) / 1e6\n",
    "    print(f\"Total polygon area: {total_area_km2:.2f} km\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61a849f3-59e6-4020-aef2-cddaebb5c772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Collect all LineStrings from all rows\n",
    "all_lines = []\n",
    "\n",
    "for geom in transition_gdf_simplified.to_crs(26915).geometry:\n",
    "    if isinstance(geom, MultiLineString):\n",
    "        # Extract individual LineStrings from MultiLineString\n",
    "        all_lines.extend(list(geom.geoms))\n",
    "    else:\n",
    "        # Single LineString case\n",
    "        all_lines.append(geom)\n",
    "\n",
    "# Now merge and polygonize all lines\n",
    "merged_lines = linemerge(all_lines)\n",
    "polygons = list(polygonize([merged_lines]))\n",
    "if polygons:\n",
    "    total_area_km2 = sum(poly.area for poly in polygons) / 1e6\n",
    "    print(f\"Total polygon area: {total_area_km2:.2f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295b4d82-86c6-424b-96a3-a941847e4fe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Collect all LineStrings from all rows\n",
    "all_lines = []\n",
    "\n",
    "for geom in g50.to_crs(26915).geometry:\n",
    "    if isinstance(geom, MultiLineString):\n",
    "        # Extract individual LineStrings from MultiLineString\n",
    "        all_lines.extend(list(geom.geoms))\n",
    "    else:\n",
    "        # Single LineString case\n",
    "        all_lines.append(geom)\n",
    "\n",
    "# Now merge and polygonize all lines\n",
    "merged_lines = linemerge(all_lines)\n",
    "polygons = list(polygonize([merged_lines]))\n",
    "if polygons:\n",
    "    total_area_km2 = sum(poly.area for poly in polygons) / 1e6\n",
    "    print(f\"Total polygon area: {total_area_km2:.2f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e5406b0-32cf-477f-a69b-ceecb2a85c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "g10.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "269b44fc-87f1-42b0-96b5-29c8f82f934d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figure 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ce1381-fa6c-4d4c-ad32-96524e9584fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outlines = [g500, g100, g50, g10]\n",
    "labels = [\"500-year\", \"100-year\", \"50-year\", \"10-year\"]\n",
    "\n",
    "colors = plt.cm.Greys(np.linspace(0.2, 0.95, len(outlines)))\n",
    "linestyles = [\"solid\", \"solid\", \"solid\", \"solid\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for g, label, ls, color in zip(outlines, labels, linestyles, colors):\n",
    "    if not g.empty:\n",
    "        g3857 = g.to_crs(3857)\n",
    "        g3857.plot(ax=ax,\n",
    "                   edgecolor='white',\n",
    "                   facecolor=color,\n",
    "                   alpha=1,\n",
    "                   linewidth=.2,\n",
    "                   linestyle=ls,\n",
    "                   zorder=5)\n",
    "g3857 = gc.to_crs(3857)\n",
    "g3857.plot(ax=ax,\n",
    "           color='black',\n",
    "           alpha=1,\n",
    "           linewidth=1,\n",
    "           zorder=5)\n",
    "\n",
    "if not transition_gdf_simplified.empty:\n",
    "    transition_gdf_3857 = transition_gdf_simplified.to_crs(3857)\n",
    "    transition_gdf_3857.plot(\n",
    "        ax=ax,\n",
    "        facecolor='none',\n",
    "        edgecolor='white',\n",
    "        linewidth=3.5,\n",
    "        linestyle='solid',\n",
    "        zorder=9,\n",
    "        hatch='//'\n",
    "    )\n",
    "    transition_gdf_3857.plot(\n",
    "        ax=ax,\n",
    "        facecolor='none',\n",
    "        edgecolor='black',\n",
    "        linewidth=1.5,\n",
    "        linestyle='dashed',\n",
    "        zorder=10\n",
    "    )\n",
    "\n",
    "valid_outlines = [g for g in outlines if not g.empty]\n",
    "if valid_outlines:\n",
    "    all_g = gpd.GeoDataFrame(pd.concat(valid_outlines, ignore_index=True), crs=valid_outlines[0].crs).to_crs(3857)\n",
    "    minx, miny, maxx, maxy = all_g.total_bounds\n",
    "    pad_x, pad_y = (maxx - minx)*0.05, (maxy - miny)*0.05\n",
    "    ax.set_xlim(minx - pad_x, maxx + pad_x)\n",
    "    ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "###############\n",
    "class HandlerOverlay(HandlerBase):\n",
    "    \"\"\"Custom handler that overlays multiple patches in one legend box.\"\"\"\n",
    "    def create_artists(self, legend, orig_handle,\n",
    "                       xdescent, ydescent, width, height, fontsize, trans):\n",
    "        artists = []\n",
    "        for h in orig_handle:\n",
    "            a = mpatches.Rectangle(\n",
    "                (xdescent, ydescent), width, height,\n",
    "                facecolor=h.get_facecolor(),\n",
    "                edgecolor=h.get_edgecolor(),\n",
    "                hatch=h.get_hatch(),\n",
    "                linestyle=h.get_linestyle(),\n",
    "                linewidth=h.get_linewidth(),\n",
    "                transform=trans\n",
    "            )\n",
    "            artists.append(a)\n",
    "        return artists\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='black', lw=1, linestyle='solid', label='Overall')\n",
    "]\n",
    "\n",
    "legend_elements += [\n",
    "    mpatches.Patch(facecolor=color, edgecolor='none', label=label)\n",
    "    for label, color in zip(reversed(labels), reversed(colors))\n",
    "]\n",
    "\n",
    "# Define the two layers of the special patch\n",
    "patch_hatch = mpatches.Patch(facecolor='lightgray', edgecolor='white', hatch='//')\n",
    "patch_outline = mpatches.Patch(facecolor='none', edgecolor='black',\n",
    "                               linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Add them as a tuple (well overlay them in one box)\n",
    "legend_elements.append((patch_hatch, patch_outline))\n",
    "\n",
    "# Labels\n",
    "labels_final = [\n",
    "    h.get_label() if not isinstance(h, tuple) else \"Bilskie & Hagen 2018\"\n",
    "    for h in legend_elements\n",
    "]\n",
    "\n",
    "ax.legend(\n",
    "    handles=legend_elements,\n",
    "    labels=labels_final,\n",
    "    handler_map={tuple: HandlerOverlay()},  # overlay instead of side-by-side\n",
    "    loc=\"lower right\",\n",
    "    bbox_to_anchor=(1.01, .01),\n",
    "    title=\"CFTZ boundaries\"\n",
    ")\n",
    "###########\n",
    "ax.text(0.22, 0.91, \"Hydrologic Flood Zone\", transform=ax.transAxes,\n",
    "        fontsize=13, fontweight='bold', va='top', ha='left', color='navy', zorder=20, rotation=20)\n",
    "ax.text(0.85, 0.43, \"Coastal Flood Zone\", transform=ax.transAxes,\n",
    "        fontsize=13, fontweight='bold', va='center', ha='right', color='darkred', zorder=20, rotation=50)\n",
    "\n",
    "# Add test labels\n",
    "ax.text(0.24, 0.43, \"10-yr\", transform=ax.transAxes, fontsize=8, color='white',\n",
    "                zorder=12,\n",
    "                path_effects=[__import__('matplotlib.patheffects').patheffects.withStroke(\n",
    "                    linewidth=2, foreground='black')])\n",
    "ax.text(0.195, 0.415, \"50-yr\", transform=ax.transAxes, fontsize=8, color='white',\n",
    "                zorder=12,\n",
    "                path_effects=[__import__('matplotlib.patheffects').patheffects.withStroke(\n",
    "                    linewidth=2, foreground='black')])\n",
    "ax.text(0.1395, 0.397, \"100-yr\", transform=ax.transAxes, fontsize=8, color='white',\n",
    "                zorder=12,\n",
    "                path_effects=[__import__('matplotlib.patheffects').patheffects.withStroke(\n",
    "                    linewidth=2, foreground='black')])\n",
    "ax.text(0.17, 0.48, \"500-yr\", transform=ax.transAxes, fontsize=8, color='white',\n",
    "                zorder=12,\n",
    "                path_effects=[__import__('matplotlib.patheffects').patheffects.withStroke(\n",
    "                    linewidth=2, foreground='black')])\n",
    "\n",
    "ax.annotate('', \n",
    "            xy=(0.04, 0.12),\n",
    "            xytext=(0.04, 0.04),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            arrowprops=dict(\n",
    "                facecolor='k', \n",
    "                edgecolor='k',\n",
    "                arrowstyle='-|>',\n",
    "                lw=3,\n",
    "                mutation_scale=20\n",
    "            ))\n",
    "ax.text(0.04, 0.15, 'N', transform=ax.transAxes, \n",
    "        ha='center', va='center', fontsize=16, fontweight='bold', color='k')\n",
    "\n",
    "def add_scalebar(ax, length_km, location=(0.08, 0.08), linewidth=4, text_offset=0.01):\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    bar_length_m = length_km * 1000\n",
    "    x_start = xlim[0] + (xlim[1] - xlim[0]) * location[0]\n",
    "    y_start = ylim[0] + (ylim[1] - ylim[0]) * location[1]\n",
    "    x_end = x_start + bar_length_m\n",
    "    ax.plot([x_start, x_end], [y_start, y_start], color='k', lw=linewidth, solid_capstyle='butt', zorder=20)\n",
    "    ax.text((x_start + x_end) / 2, y_start - (ylim[1] - ylim[0]) * text_offset,\n",
    "            f\"{length_km} km\", ha='center', va='top', fontsize=12, color='k', zorder=21)\n",
    "\n",
    "add_scalebar(ax, length_km=5, location=(0.08, 0.08), linewidth=4, text_offset=0.015)\n",
    "\n",
    "ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "plt.savefig(\"transition_compare.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "096818af-4707-482d-8216-24a18a0777a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4c8301f-2d26-4ea7-a826-e20beeb41b12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9, 7.2))\n",
    "\n",
    "# Flatten and filter real values for adaptive color range\n",
    "all_vals = np.concatenate([\n",
    "    diff_10_pluv.values.flatten(),\n",
    "    diff_50_pluv.values.flatten(),\n",
    "    diff_100_pluv.values.flatten(),\n",
    "    diff_500_pluv.values.flatten()\n",
    "])\n",
    "all_vals = all_vals[~np.isnan(all_vals) & (all_vals > 0)]\n",
    "max_val = np.percentile(all_vals, 99.5)  # true adaptive limit\n",
    "\n",
    "norm = Normalize(vmin=0, vmax=25)\n",
    "cmap = cm.get_cmap('plasma')\n",
    "\n",
    "# Plot panels with shared color scale\n",
    "img1 = diff_10_pluv.where(diff_10_pluv > difference_threshold).plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False)\n",
    "img2 = diff_50_pluv.where(diff_50_pluv > difference_threshold).plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False)\n",
    "img3 = diff_100_pluv.where(diff_100_pluv > difference_threshold).plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False)\n",
    "img4 = diff_500_pluv.where(diff_500_pluv > difference_threshold).plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False)\n",
    "\n",
    "# Basemaps and layout\n",
    "for a in ax.flat:\n",
    "    ctx.add_basemap(a, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect('equal')\n",
    "    a.set_xlabel('')\n",
    "    a.set_ylabel('')\n",
    "    a.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                  labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# Titles\n",
    "ax[0,0].set_title('10-year', fontsize=11)\n",
    "ax[0,1].set_title('50-year', fontsize=11)\n",
    "ax[1,0].set_title('100-year', fontsize=11)\n",
    "ax[1,1].set_title('500-year', fontsize=11)\n",
    "\n",
    "# Shared vertical colorbar\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.7])\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Difference in WSE (ft)\", fontsize=11)\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "# Main title\n",
    "fig.suptitle('Max(Riverine, Coastal, Pluvial) - Max(Riverine, Coastal)', fontsize=11, y=0.965)\n",
    "\n",
    "# Layout spacing\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.93, bottom=0.08, wspace=0.1, hspace=0.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41c8b049-80fb-4e92-81ac-a8019e4fe63e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figure 5\n",
    "In both feet and meters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71dda83d-066a-47c6-af64-e4d7e24f59f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9, 7.2))\n",
    "\n",
    "# Fixed color scale range - converted to meters\n",
    "vmin = 0\n",
    "vmax = 12 * 0.3048  # Convert 12 feet to meters (~3.66 m)\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "blues = plt.cm.Blues\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Blues_dark', blues(np.linspace(0.3, 1.0, 256))\n",
    ")\n",
    "\n",
    "# Convert data to meters and filter\n",
    "cd10 = (combined_depth_10 * 0.3048).where(combined_depth_10 > 0)\n",
    "cd50 = (combined_depth_50 * 0.3048).where(combined_depth_50 > 0)\n",
    "cd100 = (combined_depth_100 * 0.3048).where(combined_depth_100 > 0)\n",
    "cd500 = (combined_depth_500 * 0.3048).where(combined_depth_500 > 0)\n",
    "\n",
    "# Plot all compound flood depths\n",
    "cd10.plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "cd50.plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "cd100.plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "cd500.plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "# Basemaps and styling\n",
    "for a in ax.flat:\n",
    "    ctx.add_basemap(a, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect('equal')\n",
    "    a.set_xlabel('')\n",
    "    a.set_ylabel('')\n",
    "    a.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                  labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# Titles\n",
    "titles = ['10-year', '50-year', '100-year', '500-year']\n",
    "for i, title in enumerate(titles):\n",
    "    row, col = divmod(i, 2)\n",
    "    ax[row, col].set_title(title, fontsize=11)\n",
    "\n",
    "# Shared vertical colorbar\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.7])\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Flood Depths, m\", fontsize=11)\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "# Set explicit tick positions and labels in meters\n",
    "tick_positions = [0, 0.6096, 1.2192, 1.8288, 2.4384, 3.048, vmax]\n",
    "cb.set_ticks(tick_positions)\n",
    "cb.ax.set_yticklabels([\n",
    "    f\"{0:.1f}\",\n",
    "    f\"{0.6:.1f}\",\n",
    "    f\"{1.2:.1f}\",\n",
    "    f\"{1.8:.1f}\",\n",
    "    f\"{2.4:.1f}\",\n",
    "    f\"{3.0:.1f}\",\n",
    "    f\"$\\geq${vmax:.1f}\"\n",
    "])\n",
    "\n",
    "# Layout\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.93, bottom=0.08, wspace=0.1, hspace=0.05)\n",
    "plt.savefig(\"Compound-Flooding.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55043d97-0ff0-46ab-913f-ec7e19481711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9, 7.2))\n",
    "\n",
    "# Fixed color scale range\n",
    "vmin = 0\n",
    "vmax = 12\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "#cmap = cm.get_cmap('plasma')\n",
    "\n",
    "blues = plt.cm.Blues\n",
    "\n",
    "cmap= LinearSegmentedColormap.from_list(\n",
    "    'Blues_dark', blues(np.linspace(0.3, 1.0, 256))\n",
    ")\n",
    "\n",
    "cd10 = combined_depth_10.where(combined_depth_10 > 0)\n",
    "cd50 = combined_depth_50.where(combined_depth_50 > 0)\n",
    "cd100 = combined_depth_100.where(combined_depth_100 > 0)\n",
    "cd500 = combined_depth_500.where(combined_depth_500 > 0)\n",
    "\n",
    "# Plot all compound flood depths\n",
    "cd10.plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "cd50.plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "cd100.plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "cd500.plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "# Basemaps and styling\n",
    "for a in ax.flat:\n",
    "    ctx.add_basemap(a, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect('equal')\n",
    "    a.set_xlabel('')\n",
    "    a.set_ylabel('')\n",
    "    a.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                  labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# Titles\n",
    "titles = ['10-year', '50-year', '100-year', '500-year']\n",
    "for i, title in enumerate(titles):\n",
    "    row, col = divmod(i, 2)\n",
    "    ax[row, col].set_title(title, fontsize=11)\n",
    "\n",
    "# Shared vertical colorbar\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.7])\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Flood Depths (ft)\", fontsize=11)\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "# Modify the top label of the colorbar\n",
    "cb.ax.set_yticklabels([f\"{vmin}\",\"2\", \"4\", \"6\", \"8\", \"10\", f\"$\\geq${vmax}\"])\n",
    "\n",
    "# Title\n",
    "#fig.suptitle('Compound Flood Depths (ft)', fontsize=11, y=0.965)\n",
    "\n",
    "# Layout\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.93, bottom=0.08, wspace=0.1, hspace=0.05)\n",
    "plt.savefig(\"Compound-Flooding.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5da598f9-dbbe-44d2-831a-d0c255155d2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f1a13a-c988-4ace-a1ac-9b6a774b0b80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9, 7.2))\n",
    "\n",
    "# Colorbar range - converted to meters\n",
    "vmin, vmax = 0, 4 * 0.3048  # Convert 4 feet to meters (~1.22 m)\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "blues = plt.cm.Blues\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Blues_dark', blues(np.linspace(0.3, 1.0, 256))\n",
    ")\n",
    "\n",
    "# Convert data to meters and plot panels without colorbars\n",
    "(nt_contribution_10 * 0.3048).plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "(nt_contribution_50 * 0.3048).plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "(nt_contribution_100 * 0.3048).plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "(nt_contribution_500 * 0.3048).plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "# Add basemap + cleanup\n",
    "for a in ax.flat:\n",
    "    ctx.add_basemap(a, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect('equal')\n",
    "    a.set_xlabel('')\n",
    "    a.set_ylabel('')\n",
    "    a.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                  labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# Overlay zone outlines as boundaries for visibility\n",
    "g10.to_crs(26915).plot(ax=ax[0,0], color='tab:red', linewidth=.45, zorder=10)\n",
    "g50.to_crs(26915).plot(ax=ax[0,1], color='tab:red', linewidth=.45, zorder=10)\n",
    "g100.to_crs(26915).plot(ax=ax[1,0], color='tab:red', linewidth=.45, zorder=10)\n",
    "g500.to_crs(26915).plot(ax=ax[1,1], color='tab:red', linewidth=.45, zorder=10)\n",
    "\n",
    "# Titles\n",
    "titles = ['10-year', '50-year', '100-year', '500-year']\n",
    "for i, title in enumerate(titles):\n",
    "    row, col = divmod(i, 2)\n",
    "    ax[row, col].set_title(title, fontsize=11)\n",
    "\n",
    "# overlay the Amite transect with 0/20/40/60/80 km marks slightly right of center on EACH panel\n",
    "for a in ax.flat:\n",
    "    overlay_transect(a, fixed_line, km_ticks=(0,20,40,60,80,100,115),\n",
    "                     line_lw=.5, dot_size=15, label_fontsize=7,\n",
    "                     ensure_north_start=False, label_position='right')\n",
    "\n",
    "# Shared vertical colorbar with explicit tick positions\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.7])\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Contribution to WSE, m\", fontsize=11)\n",
    "\n",
    "# Set explicit tick positions in meters (0, 1, 2, 3, 4 feet converted)\n",
    "tick_positions = [0, 0.3048, 0.6096, 0.9144, vmax]\n",
    "cb.set_ticks(tick_positions)\n",
    "cb.ax.set_yticklabels([\n",
    "    f\"{0:.1f}\",\n",
    "    f\"{0.3:.1f}\",\n",
    "    f\"{0.6:.1f}\",\n",
    "    f\"{0.9:.1f}\",\n",
    "    f\"$\\\\geq${vmax:.1f}\"\n",
    "])\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "# Final layout adjustments\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.93, bottom=0.08, wspace=0.1, hspace=0.05)\n",
    "plt.savefig(\"Non-tropical-Contributation.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c3834e7-e5f2-40e5-8240-069b9cdde9ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import contextily as ctx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(9, 7.2))\n",
    "\n",
    "# Colorbar range\n",
    "vmin, vmax = 0, 4\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "#cmap = cm.get_cmap('plasma')\n",
    "\n",
    "blues = plt.cm.Blues\n",
    "\n",
    "cmap= LinearSegmentedColormap.from_list(\n",
    "    'Blues_dark', blues(np.linspace(0.3, 1.0, 256))\n",
    ")\n",
    "\n",
    "# Plot panels without colorbars\n",
    "nt_contribution_10.plot(ax=ax[0,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "nt_contribution_50.plot(ax=ax[0,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "nt_contribution_100.plot(ax=ax[1,0], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "nt_contribution_500.plot(ax=ax[1,1], cmap=cmap, norm=norm, add_colorbar=False, rasterized=True)\n",
    "\n",
    "\n",
    "# Add basemap + cleanup\n",
    "for a in ax.flat:\n",
    "    ctx.add_basemap(a, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "    a.set_aspect('equal')\n",
    "    a.set_xlabel('')\n",
    "    a.set_ylabel('')\n",
    "    a.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                  labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# Overlay zone outlines as boundaries for visibility\n",
    "g10.to_crs(26915).plot(ax=ax[0,0], color='tab:red', linewidth=.45, zorder=10)\n",
    "g50.to_crs(26915).plot(ax=ax[0,1], color='tab:red', linewidth=.45, zorder=10)\n",
    "g100.to_crs(26915).plot(ax=ax[1,0], color='tab:red', linewidth=.45, zorder=10)\n",
    "g500.to_crs(26915).plot(ax=ax[1,1], color='tab:red', linewidth=.45, zorder=10)\n",
    "\n",
    "# Titles\n",
    "titles = ['10-year', '50-year', '100-year', '500-year']\n",
    "for i, title in enumerate(titles):\n",
    "    row, col = divmod(i, 2)\n",
    "    ax[row, col].set_title(title, fontsize=11)\n",
    "\n",
    "# overlay the Amite transect with 0/20/40/60/80 km marks slightly right of center on EACH panel\n",
    "# (set ensure_north_start=True if you want \"0\" forced to the top/north)\n",
    "for a in ax.flat:\n",
    "    overlay_transect(a, fixed_line, km_ticks=(0,20,40,60,80,100,115),\n",
    "                     line_lw=.5, dot_size=15, label_fontsize=7,\n",
    "                     ensure_north_start=False, label_position='right')\n",
    "\n",
    "# Shared vertical colorbar with triangle tips\n",
    "cbar_ax = fig.add_axes([0.915, 0.16, 0.02, 0.7])\n",
    "cb = ColorbarBase(cbar_ax, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label(\"Contribution to WSE (ft)\", fontsize=11)\n",
    "ticks = [vmin, 1, 2, 3, vmax]\n",
    "cb.set_ticks(ticks)\n",
    "cb.ax.set_yticklabels([f\"{vmin}\",\"1\",\"2\",\"3\",f\"$\\\\geq${vmax}\"])\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "cb.outline.set_visible(False)\n",
    "\n",
    "\n",
    "# Main title\n",
    "#fig.suptitle(\"Contribution of NonTC to Combined flood depths (ft)\", fontsize=11, y=0.965)\n",
    "\n",
    "# Final layout adjustments\n",
    "plt.subplots_adjust(left=0.05, right=0.89, top=0.93, bottom=0.08, wspace=0.1, hspace=0.05)\n",
    "plt.savefig(\"Non-tropical-Contributation.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636a4aa0-4212-4eba-aa68-309961c5f185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Examine Transect of NT contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "381f4619-aef2-4bb4-a7f7-8ba511e3a85b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Apply Gaussian smoothing to the values\n",
    "smoothed_values_10 = gaussian_filter(values_10, sigma=1)\n",
    "\n",
    "# Use smoothed_values_10 for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e08f48a-dc60-407d-8134-e3d3c8434430",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "#I couldn't figure out how to fix order issues with the amite line in arcpro, so we do it here\n",
    "fixed_line = ensure_connected_linestring(amite_line.geometry[0])\n",
    "fixed_line_gdf = gpd.GeoDataFrame({'geometry': [fixed_line]}, crs = 'EPSG:26915')\n",
    "\n",
    "distances, values_10 = extract_raster_along_line(nt_contribution_10, fixed_line_gdf)\n",
    "smoothed_values_10 = gaussian_filter(values_10, sigma=5)\n",
    "distances, values_50 = extract_raster_along_line(nt_contribution_50, fixed_line_gdf)\n",
    "smoothed_values_50 = gaussian_filter(values_50, sigma=5)\n",
    "distances, values_100 = extract_raster_along_line(nt_contribution_100, fixed_line_gdf)\n",
    "smoothed_values_100 = gaussian_filter(values_100, sigma=5)\n",
    "distances, values_500 = extract_raster_along_line(nt_contribution_500, fixed_line_gdf)\n",
    "smoothed_values_500 = gaussian_filter(values_500, sigma=5)\n",
    "\n",
    "distances, compound_10_values = extract_raster_along_line(compound_10, fixed_line_gdf)\n",
    "distances, compound_50_values = extract_raster_along_line(compound_50, fixed_line_gdf)\n",
    "distances, compound_100_values = extract_raster_along_line(compound_100, fixed_line_gdf)\n",
    "distances, compound_500_values = extract_raster_along_line(compound_500, fixed_line_gdf)\n",
    "\n",
    "distances, pluvial_surge_riverine_10_values = extract_raster_along_line(pluvial_surge_riverine_10, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_50_values = extract_raster_along_line(pluvial_surge_riverine_50, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_100_values = extract_raster_along_line(pluvial_surge_riverine_100, fixed_line_gdf)\n",
    "distances, pluvial_surge_riverine_500_values = extract_raster_along_line(pluvial_surge_riverine_500, fixed_line_gdf)\n",
    "\n",
    "fig = plt.figure(figsize=(7.5, 12))  # academic width ~7.5 inches\n",
    "\n",
    "gs = fig.add_gridspec(5, 2)\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 0])\n",
    "ax3 = fig.add_subplot(gs[3, 0])\n",
    "ax4 = fig.add_subplot(gs[4, 0])\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax7 = fig.add_subplot(gs[3, 1])\n",
    "ax8 = fig.add_subplot(gs[4, 1])\n",
    "ax9 = fig.add_subplot(gs[0, :])  # overview map\n",
    "\n",
    "# Plot lines - Left column: solid (Compound), dashed (Max of 3)\n",
    "ax1.plot(distances/1000, compound_10_values, linestyle='-', color='black')\n",
    "ax1.plot(distances/1000, pluvial_surge_riverine_10_values, linestyle='--', color='black')\n",
    "ax2.plot(distances/1000, compound_50_values, linestyle='-', color='black')\n",
    "ax2.plot(distances/1000, pluvial_surge_riverine_50_values, linestyle='--', color='black')\n",
    "ax3.plot(distances/1000, compound_100_values, linestyle='-', color='black')\n",
    "ax3.plot(distances/1000, pluvial_surge_riverine_100_values, linestyle='--', color='black')\n",
    "ax4.plot(distances/1000, compound_500_values, linestyle='-', color='black')\n",
    "ax4.plot(distances/1000, pluvial_surge_riverine_500_values, linestyle='--', color='black')\n",
    "\n",
    "# Right column: Difference plots (black)\n",
    "ax5.plot(distances/1000, smoothed_values_10, color='black')\n",
    "ax6.plot(distances/1000, smoothed_values_50, color='black')\n",
    "ax7.plot(distances/1000, smoothed_values_100, color='black')\n",
    "ax8.plot(distances/1000, smoothed_values_500, color='black')\n",
    "\n",
    "# Set y-axis limits for right column\n",
    "for ax in [ax5, ax6, ax7, ax8]:\n",
    "    ax.set_ylim(0, 4)\n",
    "\n",
    "# Set x-axis ticks for right column to every 10 km\n",
    "for ax in [ax5, ax6, ax7, ax8]:\n",
    "    ax.set_xticks(np.arange(0, distances.max()/1000 + 10, 10))\n",
    "\n",
    "# Labels\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_ylabel('WSE (ft)', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "\n",
    "for ax in [ax5, ax6, ax7, ax8]:\n",
    "    ax.set_ylabel('WSE Difference (ft)', fontsize=11)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=11)\n",
    "    ax.tick_params(labelsize=11)\n",
    "\n",
    "# Titles\n",
    "ax1.set_title('10-year', fontsize=11)\n",
    "ax2.set_title('50-year', fontsize=11)\n",
    "ax3.set_title('100-year', fontsize=11)\n",
    "ax4.set_title('500-year', fontsize=11)\n",
    "ax5.set_title('10-year', fontsize=11)\n",
    "ax6.set_title('50-year', fontsize=11)\n",
    "ax7.set_title('100-year', fontsize=11)\n",
    "ax8.set_title('500-year', fontsize=11)\n",
    "\n",
    "#fig.suptitle('Difference between compound flood depths and max of 3 individual drivers along Amite transect', fontsize=11)\n",
    "\n",
    "# Top map\n",
    "ax9.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "fixed_line_gdf.plot(ax=ax9)\n",
    "domain_gdf.exterior.plot(ax=ax9)\n",
    "ctx.add_basemap(ax9, crs=\"EPSG:26915\", source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "# Custom legend for left column\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig.subplots_adjust(top=0.96, hspace=0.6, wspace=0.3)\n",
    "\n",
    "# Custom line styles\n",
    "legend_elements_left = [\n",
    "    Line2D([0], [0], linestyle='-', color='black', label='Compounded Flood Elevation'),\n",
    "    Line2D([0], [0], linestyle='--', color='black', label='Max of Pluvial, Fluvial, and Coastal Drivers')\n",
    "]\n",
    "\n",
    "from matplotlib.patches import Patch  # add this import at the top if not already present\n",
    "\n",
    "legend_elements_right = [\n",
    "    Patch(facecolor='none', edgecolor='none', label='Flood Depth Difference of Compound Flood\\nand Max of Pluvial, Fluvial, and Coastal Drivers')\n",
    "]\n",
    "\n",
    "#Axes for placing column legends\n",
    "ax_legend_left = fig.add_axes([0.07, 0.79, 0.42, 0.05])   # [left, bottom, width, height]\n",
    "ax_legend_right = fig.add_axes([0.52, 0.79, 0.42, 0.05])\n",
    "\n",
    "# Turn off everything for dummy axes\n",
    "for ax in [ax_legend_left, ax_legend_right]:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Left column legend\n",
    "ax_legend_left.legend(\n",
    "    handles=legend_elements_left,\n",
    "    loc='center',\n",
    "    fontsize=10,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# Right column legend\n",
    "ax_legend_right.legend(\n",
    "    handles=legend_elements_right,\n",
    "    loc='center',\n",
    "    fontsize=10,\n",
    "    frameon=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1ff329d-14a9-4910-b22a-003ea023ca22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Figs. 5, 6, 7, 8, 9, 13",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
